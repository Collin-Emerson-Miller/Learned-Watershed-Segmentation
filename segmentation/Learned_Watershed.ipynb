{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import segmentation\n",
    "import time\n",
    "\n",
    "import BachNet\n",
    "import ChopinNet\n",
    "import utils\n",
    "import shutil\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train/input/\"\n",
    "test_path = \"data/test/input/\"\n",
    "\n",
    "output_path = \"output\"\n",
    "\n",
    "path_to_original_images = \"original/\"\n",
    "path_to_gt_images = \"gt/\"\n",
    "\n",
    "receptive_field_shape = (23, 23)\n",
    "\n",
    "bach = BachNet.BachNet()\n",
    "chopin = ChopinNet.Chopin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bach.build(receptive_field_shape[0], receptive_field_shape[1], 1)\n",
    "bach.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "originals = os.listdir(os.path.join(train_path))\n",
    "\n",
    "for i, filename in enumerate(originals):\n",
    "    \n",
    "    if \"gt\" in filename.split(\"_\"):\n",
    "        continue\n",
    "    \n",
    "    gt_filename = filename + \"_gt\"\n",
    "    \n",
    "    image_path = os.path.join(train_path, filename)\n",
    "    gt_path = os.path.join(train_path, gt_filename)\n",
    "    \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    gt = cv2.imread(gt_path, 0)\n",
    "    \n",
    "    if gt is None:\n",
    "        continue\n",
    "    \n",
    "    x = utils.prepare_input_images(img, width=receptive_field_shape[0],\n",
    "                                   height=receptive_field_shape[1])\n",
    "    \n",
    "    X.append(x)\n",
    "\n",
    "    gt = cv2.imread(gt_path, 0)\n",
    "    y = np.zeros_like(gt)\n",
    "    y[gt == 255] = 1\n",
    "    y = y.flatten()\n",
    "    \n",
    "    Y.append(y)\n",
    "    \n",
    "X = np.concatenate(X)\n",
    "Y = np.concatenate(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bach.model.fit(X, Y, batch_size=1000, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originals = os.listdir(os.path.join(train_path))\n",
    "\n",
    "for i, filename in enumerate(originals):\n",
    "    \n",
    "    if \"gt\" in filename.split(\"_\"):\n",
    "        continue\n",
    "    \n",
    "    image_path = os.path.join(train_path, filename)\n",
    "    \n",
    "    img = cv2.imread(image_path, 0)\n",
    "\n",
    "    bach_filename = \"data/train/bach/\" + filename\n",
    "\n",
    "    boundary_probabilities = bach.boundary_probabilities(img, batch_size=3000, verbose=1)\n",
    "\n",
    "    plt.imsave(bach_filename, boundary_probabilities, cmap='gray')\n",
    "\n",
    "    bach.model.save('saved_model/Bach/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originals = os.listdir(os.path.join(train_path))\n",
    "\n",
    "number_files = len(originals)\n",
    "\n",
    "progress = 0\n",
    "\n",
    "for i, filename in enumerate(originals):\n",
    "    \n",
    "    if \"gt\" in filename.split(\"_\"):\n",
    "        continue\n",
    "        \n",
    "    sys.stdout.write(\"\\nTotal Progress: [%d%%]\\n\" % progress)\n",
    "    progress = i + 1 / number_files * 100\n",
    "    \n",
    "    gt_filename = filename + \"_gt\"\n",
    "    \n",
    "    image_path = os.path.join(train_path, filename)\n",
    "    gt_path = os.path.join(train_path, gt_filename)\n",
    "    \n",
    "    print(\"Now training on\", filename)\n",
    "    print(\"---------------------------\\n\")\n",
    "    \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    gt = cv2.imread(gt_path, 0)\n",
    "    \n",
    "    foldername = \"data/train/chopin/\" + filename\n",
    "    if os.path.exists(foldername):\n",
    "        shutil.rmtree(foldername)\n",
    "    \n",
    "    os.makedirs(foldername)\n",
    "        \n",
    "    os.system(\"gmic -v -1 data/train/input/\" + gt_filename + \" -channels 1 -threshold 10% -negative -label_fg 0,0 -o -.asc | tail -n +2 | awk '{ for (i = 1; i<=NF; i++) {x[$i] += i; y[$i] += NR; n[$i]++; } } END { for (v in x) print x[v]/n[v],y[v]/n[v] }' > \" + foldername + \"/seeds.txt\")\n",
    "    \n",
    "    seeds = []\n",
    "    f = open(foldername + \"/seeds.txt\", 'r')\n",
    "    for line in f:\n",
    "        y = int(float(re.split(' ', line)[0]))\n",
    "        x = int(float(re.split(' ', line)[1]))\n",
    "        seed = (x - 1, y - 1)\n",
    "        seeds.append(seed)\n",
    "\n",
    "    seeds = seeds[1:]\n",
    "    \n",
    "    \n",
    "    boundary_probabilties, segmentations, loss_timeline, accuracy_timeline = ChopinNet.fit(img,\n",
    "                                                                                            gt,\n",
    "                                                                                            seeds,\n",
    "                                                                                            num_epochs=32)\n",
    "    plt.plot(loss_timeline)\n",
    "    plt.savefig(os.path.join(foldername, \"loss.png\"))\n",
    "    plt.clf()   # Clear figure\n",
    "    \n",
    "    for i, seg in enumerate(segmentations):\n",
    "        mask = utils.transparent_mask(img, seg, alpha=0.7)\n",
    "        epoch = \"Epoch \" + str(i + 1)\n",
    "        plt.imsave(os.path.join(foldername, epoch), mask)\n",
    "    \n",
    "sys.stdout.write(\"\\nDone!: [100%]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "originals = os.listdir(os.path.join(test_path))\n",
    "\n",
    "number_files = len(originals)\n",
    "\n",
    "progress = 0\n",
    "\n",
    "for i, filename in enumerate(originals):\n",
    "    \n",
    "    if \"gt\" in filename.split(\"_\"):\n",
    "        continue\n",
    "        \n",
    "    sys.stdout.write(\"\\nTotal Progress: [%d%%]\\n\" % progress)\n",
    "    progress = i + 1 / number_files * 100\n",
    "    \n",
    "    gt_filename = filename + \"_gt\"\n",
    "    \n",
    "    image_path = os.path.join(test_path, filename)\n",
    "    gt_path = os.path.join(test_path, gt_filename)\n",
    "    \n",
    "    print(\"Now testing on\", filename)\n",
    "    print(\"---------------------------\\n\")\n",
    "    \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    x = utils.prepare_input_images(img)\n",
    "    \n",
    "    b_probs = b_net.boundary_probabilities(img, batch_size=3000, verbose=1)\n",
    "    \n",
    "    bach_filename = \"data/test/bach/\" + filename\n",
    "    plt.imsave(bach_filename, b_probs, cmap='gray')\n",
    "    \n",
    "sys.stdout.write(\"\\nDone!: [100%]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originals = os.listdir(os.path.join(test_path))\n",
    "\n",
    "number_files = len(originals)\n",
    "\n",
    "progress = 0\n",
    "\n",
    "for i, filename in enumerate(originals):\n",
    "    \n",
    "    if \"gt\" in filename.split(\"_\"):\n",
    "        continue\n",
    "        \n",
    "    sys.stdout.write(\"\\nTotal Progress: [%d%%]\\n\" % progress)\n",
    "    progress = i + 1 / number_files * 100\n",
    "    \n",
    "    gt_filename = filename + \"_gt\"\n",
    "    \n",
    "    image_path = os.path.join(test_path, filename)\n",
    "    gt_path = os.path.join(test_path, gt_filename)\n",
    "    \n",
    "    print(\"Now training on\", filename)\n",
    "    print(\"---------------------------\\n\")\n",
    "    \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    gt = cv2.imread(gt_path, 0)\n",
    "    \n",
    "    foldername = \"data/test/chopin/\" + filename\n",
    "    if os.path.exists(foldername):\n",
    "        shutil.rmtree(foldername)\n",
    "    \n",
    "    os.makedirs(foldername)\n",
    "        \n",
    "    os.system(\"gmic -v -1 data/test/input/\" + gt_filename + \" -channels 1 -threshold 10% -negative -label_fg 0,0 -o -.asc | tail -n +2 | awk '{ for (i = 1; i<=NF; i++) {x[$i] += i; y[$i] += NR; n[$i]++; } } END { for (v in x) print x[v]/n[v],y[v]/n[v] }' > \" + foldername + \"/seeds.txt\")\n",
    "    \n",
    "    seeds = []\n",
    "    f = open(foldername + \"/seeds.txt\", 'r')\n",
    "    for line in f:\n",
    "        y = int(float(re.split(' ', line)[0]))\n",
    "        x = int(float(re.split(' ', line)[1]))\n",
    "        seed = (x - 1, y - 1)\n",
    "        seeds.append(seed)\n",
    "\n",
    "    seeds = seeds[1:]\n",
    "    \n",
    "    seg = ChopinNet.predict(img, seeds)\n",
    "    \n",
    "    mask = utils.transparent_mask(img, seg, alpha=0.5)\n",
    "    plt.imsave(os.path.join(foldername, filename), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
