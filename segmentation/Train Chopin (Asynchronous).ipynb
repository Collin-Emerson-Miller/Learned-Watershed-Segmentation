{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from models import BachNet\n",
    "from models import ChopinNet\n",
    "\n",
    "import networkx as nx\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from heapq import heappop as pop\n",
    "from heapq import heappush as push\n",
    "from utils import graph_utils\n",
    "from utils import display_utils\n",
    "from utils import prediction_utils\n",
    "from utils import preprocessing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "test_path = \"data/test\"\n",
    "\n",
    "input_path = \"input\"\n",
    "output_path = \"output\"\n",
    "\n",
    "gt_tag = \"gt\"\n",
    "\n",
    "receptive_field_shape = (12, 12)\n",
    "n_epochs = 128\n",
    "save_rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find model. Creating a new one.\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to create file (Unable to open file: name = 'models/saved_models/bach/model.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4acc7ec168cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBachNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBachNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceptive_field_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/saved_models/Bach/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/collin/PycharmProjects/Learned-Watershed-Segmentation/segmentation/models/BachNet.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find model. Creating a new one.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceptive_field_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \"\"\"\n\u001b[1;32m   2505\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2506\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to create file (Unable to open file: name = 'models/saved_models/bach/model.h5', errno = 2, error message = 'no such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "bach = BachNet.BachNet()\n",
    "bach.build(receptive_field_shape, 1)\n",
    "bach.load_model('models/saved_models/Bach/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image:  slice_59\n",
      "Loading image:  slice_59\n"
     ]
    }
   ],
   "source": [
    "batch = dict()\n",
    "input_gen = prediction_utils.input_generator(bach, train_path, input_path, gt_tag)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        f_name, img, bps, I_a, gt, gt_cuts, seeds = next(input_gen)\n",
    "        graph = graph_utils.prims_initialize(img)\n",
    "        batch[f_name] = img, bps, I_a, gt, gt_cuts, seeds, graph\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chopin = ChopinNet.Chopin()\n",
    "chopin.build(receptive_field_shape, learning_rate=1e-5)\n",
    "#chopin.load_model(\"models/saved_model/Chopin/checkpoint\")\n",
    "chopin.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.726454s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035326s\n",
      "6.30839395523\n",
      "Loss:  46.7537689209\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.720744s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033008s\n",
      "6.14571022987\n",
      "Loss:  5.25823879242\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.856825s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035038s\n",
      "Saving Model\n",
      "12.9248030186\n",
      "Loss:  6.20071411133\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.828446s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034598s\n",
      "Saving Model\n",
      "12.3658339977\n",
      "Loss:  25.2894668579\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.767020s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036274s\n",
      "Saving Model\n",
      "13.3352379799\n",
      "Loss:  4.51704454422\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.882343s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034801s\n",
      "Saving Model\n",
      "14.039992094\n",
      "Loss:  5.68687009811\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.730250s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036714s\n",
      "Saving Model\n",
      "13.5037710667\n",
      "Loss:  12.808883667\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.753755s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036033s\n",
      "Saving Model\n",
      "13.7995159626\n",
      "Loss:  0.0850464701653\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.745915s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035860s\n",
      "Saving Model\n",
      "14.8191649914\n",
      "Loss:  8.74296283722\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.753773s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035056s\n",
      "Saving Model\n",
      "14.1506528854\n",
      "Loss:  1.07693684101\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.790395s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.037098s\n",
      "Saving Model\n",
      "15.9580490589\n",
      "Loss:  1.71811032295\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.758162s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034724s\n",
      "Saving Model\n",
      "14.9137661457\n",
      "Loss:  3.12872314453\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.749470s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034866s\n",
      "Saving Model\n",
      "14.8961098194\n",
      "Loss:  1.14616537094\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.742011s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034567s\n",
      "Saving Model\n",
      "16.1549520493\n",
      "Loss:  1.23236620426\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.747380s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034404s\n",
      "Saving Model\n",
      "16.0788829327\n",
      "Loss:  8.91859436035\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.744299s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034582s\n",
      "Saving Model\n",
      "16.2107810974\n",
      "Loss:  0.535031378269\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.737848s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035042s\n",
      "Saving Model\n",
      "14.5589909554\n",
      "Loss:  1.70665085316\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.748260s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033666s\n",
      "Saving Model\n",
      "18.3388459682\n",
      "Loss:  0.53515958786\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.730860s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036752s\n",
      "Saving Model\n",
      "14.8727440834\n",
      "Loss:  2.00838041306\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.796022s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035137s\n",
      "Saving Model\n",
      "17.1255919933\n",
      "Loss:  0.406923055649\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.749606s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035818s\n",
      "6.15401887894\n",
      "Loss:  2.30015563965\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.761625s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033971s\n",
      "6.09832906723\n",
      "Loss:  0.520224630833\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.745093s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035784s\n",
      "Saving Model\n",
      "15.6982738972\n",
      "Loss:  1.83258283138\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.739579s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.532329s\n",
      "Saving Model\n",
      "18.4446909428\n",
      "Loss:  0.415445804596\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.744323s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036275s\n",
      "Saving Model\n",
      "16.8221280575\n",
      "Loss:  0.336337566376\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.739646s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035624s\n",
      "Saving Model\n",
      "19.1601288319\n",
      "Loss:  0.341267228127\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.731252s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036082s\n",
      "Saving Model\n",
      "18.0137431622\n",
      "Loss:  0.564116954803\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.781271s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033666s\n",
      "Saving Model\n",
      "20.6228730679\n",
      "Loss:  0.439522027969\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.732370s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034824s\n",
      "Saving Model\n",
      "19.1104049683\n",
      "Loss:  1.14549255371\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.738453s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034255s\n",
      "Saving Model\n",
      "20.6372840405\n",
      "Loss:  0.334879636765\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.732567s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034845s\n",
      "Saving Model\n",
      "17.9262270927\n",
      "Loss:  0.263698577881\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.736628s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033540s\n",
      "Saving Model\n",
      "21.4176938534\n",
      "Loss:  0.242269635201\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.752830s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034117s\n",
      "Saving Model\n",
      "20.26293993\n",
      "Loss:  0.144556045532\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.778570s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033979s\n",
      "Saving Model\n",
      "21.4884719849\n",
      "Loss:  3.47389793396\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.742416s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.037081s\n",
      "Saving Model\n",
      "20.6721918583\n",
      "Loss:  0.246040523052\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.737392s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034740s\n",
      "Saving Model\n",
      "21.5043230057\n",
      "Loss:  0.12374073267\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.760606s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036644s\n",
      "Saving Model\n",
      "21.5000658035\n",
      "Loss:  0.182778954506\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.735097s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.037366s\n",
      "Saving Model\n",
      "22.375412941\n",
      "Loss:  0.419229984283\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.751332s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035158s\n",
      "Saving Model\n",
      "22.4067938328\n",
      "Loss:  0.599710941315\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.744178s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036066s\n",
      "Saving Model\n",
      "24.3548099995\n",
      "Loss:  0.671864628792\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.776142s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035849s\n",
      "6.16175508499\n",
      "Loss:  0.438748836517\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.757549s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034367s\n",
      "6.08465886116\n",
      "Loss:  0.582950472832\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation done: 5.750629s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035316s\n",
      "Saving Model\n",
      "22.8120191097\n",
      "Loss:  0.417468070984\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.768264s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036374s\n",
      "Saving Model\n",
      "25.5945081711\n",
      "Loss:  0.650390565395\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.751294s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035480s\n",
      "Saving Model\n",
      "24.0462620258\n",
      "Loss:  0.476050078869\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.806616s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035004s\n",
      "Saving Model\n",
      "24.4806349277\n",
      "Loss:  0.558739542961\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.758995s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035356s\n",
      "Saving Model\n",
      "24.6667439938\n",
      "Loss:  0.475578308105\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.748915s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033888s\n",
      "Saving Model\n",
      "26.4486730099\n",
      "Loss:  0.480094909668\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.746034s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035240s\n",
      "Saving Model\n",
      "25.6020569801\n",
      "Loss:  0.407585561275\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.758511s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034864s\n",
      "Saving Model\n",
      "26.9552750587\n",
      "Loss:  0.298884987831\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.751432s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034387s\n",
      "Saving Model\n",
      "26.3766739368\n",
      "Loss:  0.338992357254\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.758192s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036939s\n",
      "Saving Model\n",
      "27.8022649288\n",
      "Loss:  0.0711022615433\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.770593s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033394s\n",
      "Saving Model\n",
      "27.9590661526\n",
      "Loss:  -0.186813831329\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.794077s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034742s\n",
      "Saving Model\n",
      "27.4878528118\n",
      "Loss:  0.827701449394\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.779596s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035162s\n",
      "Saving Model\n",
      "30.7977690697\n",
      "Loss:  0.207767963409\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.756077s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035697s\n",
      "Saving Model\n",
      "29.3267550468\n",
      "Loss:  -0.0260344743729\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.766262s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035735s\n",
      "Saving Model\n",
      "29.8864040375\n",
      "Loss:  0.130521893501\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.765045s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034349s\n",
      "Saving Model\n",
      "30.865172863\n",
      "Loss:  0.650924682617\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.764461s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035362s\n",
      "Saving Model\n",
      "29.5776109695\n",
      "Loss:  0.242532253265\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.764759s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036408s\n",
      "Saving Model\n",
      "30.8011310101\n",
      "Loss:  0.892235696316\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.804668s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033326s\n",
      "6.20141386986\n",
      "Loss:  0.245737075806\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.762195s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034813s\n",
      "6.31086397171\n",
      "Loss:  0.131028413773\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.768232s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035698s\n",
      "Saving Model\n",
      "30.9020950794\n",
      "Loss:  0.203092575073\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.771886s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.032911s\n",
      "Saving Model\n",
      "33.6424670219\n",
      "Loss:  0.0311019420624\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.748384s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035861s\n",
      "Saving Model\n",
      "32.3483939171\n",
      "Loss:  -0.242995738983\n",
      "Training on: 740_1450\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.901644s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036149s\n",
      "Saving Model\n",
      "33.4833409786\n",
      "Loss:  0.132974863052\n",
      "Training on: 740_1460\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.946671s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036543s\n",
      "Saving Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-116da98c05f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mchopin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saved_models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mchopin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/saved_models/Chopin/chopin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/PycharmProjects/Learned-Watershed-Segmentation/segmentation/models/ChopinNet.pyc\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, filepath, global_step)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredicted_msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1494\u001b[0m           checkpoint_file, meta_graph_suffix=meta_graph_suffix)\n\u001b[1;32m   1495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     return export_meta_graph(\n\u001b[1;32m   1527\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m         \u001b[0msaver_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0mcollection_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2483\u001b[0m     \"\"\"\n\u001b[1;32m   2484\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2485\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2486\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"_output_shapes\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m             graph.node[-1].attr[\"_output_shapes\"].list.shape.extend([\n\u001b[0;32m-> 2443\u001b[0;31m                 output.get_shape().as_proto() for output in op.outputs])\n\u001b[0m\u001b[1;32m   2444\u001b[0m           \u001b[0mbytesize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mas_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m           tensor_shape_pb2.TensorShapeProto.Dim(size=-1\n\u001b[1;32m    803\u001b[0m                                                 if d.value is None else d.value)\n\u001b[0;32m--> 804\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m       ])\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3096ad0110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_loss_timeline = []\n",
    "loss_timelines = dict()\n",
    "loss_file = open(\"data/train/chopin/global_loss.txt\", 'w')\n",
    "loss_file.write(\"f_name\\tepoch\\tloss\\n\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for f_name, (img, bps, I_a, gt, gt_cuts, seeds, graph) in batch.iteritems():\n",
    "        print(\"Training on:\", f_name)\n",
    "        \n",
    "        foldername = os.path.join(train_path, \"chopin\", f_name)\n",
    "        start = time.time()\n",
    "        \n",
    "        loss, segmentations, cuts = chopin.train_on_image(img, I_a, gt_cuts, seeds, graph)\n",
    "        \n",
    "        if epoch % save_rate:\n",
    "            print(\"Saving Model\")\n",
    "            chopin.save_model(os.path.join(foldername, \"saved_models\", \"model\"), epoch)\n",
    "            chopin.save_model(\"models/saved_models/Chopin/chopin\", epoch)\n",
    "        \n",
    "        print(time.time() - start)\n",
    "        print(\"Loss: \", loss)\n",
    "        \n",
    "        plt.imsave(os.path.join(foldername, \"epoch_{}_bw.png\".format(epoch)), display_utils.view_boundaries(np.zeros_like(img), cuts))\n",
    "\n",
    "        mask = display_utils.transparent_mask(display_utils.view_boundaries(img, gt_cuts), segmentations, alpha=0.75)\n",
    "        plt.imsave(os.path.join(foldername, \"epoch_{}_overlay.png\".format(epoch)), mask)\n",
    "        \n",
    "        loss_file.write(f_name + \"\\t\" + str(epoch) + \"\\t\" + str(loss) + \"\\n\")\n",
    "        loss_file.flush()\n",
    "        \n",
    "        global_loss_timeline.append(loss)\n",
    "        \n",
    "        try:\n",
    "            loss_timelines[f_name].append(loss)\n",
    "        except KeyError:\n",
    "            loss_timelines[f_name] = [loss]\n",
    "            \n",
    "        plt.plot(loss_timelines[f_name])\n",
    "        plt.savefig(os.path.join(foldername, \"local_loss\"))\n",
    "        \n",
    "        plt.gcf().clear()\n",
    "            \n",
    "        plt.plot(global_loss_timeline)\n",
    "        plt.savefig(\"data/train/chopin/global_loss\")\n",
    "        \n",
    "        plt.gcf().clear()\n",
    "            \n",
    "loss_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
