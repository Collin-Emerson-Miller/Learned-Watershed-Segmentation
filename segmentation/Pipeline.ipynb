{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import copy\n",
    "import itertools\n",
    "import keras\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import scipy.misc\n",
    "import sklearn.feature_extraction\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import threading\n",
    "import gc\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy import ndimage\n",
    "from heapq import heappush, heappop\n",
    "from networkx_viewer import Viewer\n",
    "from matplotlib import colors as mcolors\n",
    "from sys import stdout\n",
    "from __future__ import division\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_edges_3d(n_x, n_y, n_z=1):\n",
    "    \"\"\"Returns a list of edges for a 3D image.\n",
    "    Parameters\n",
    "    ===========\n",
    "    n_x: integer\n",
    "        The size of the grid in the x direction.\n",
    "    n_y: integer\n",
    "        The size of the grid in the y direction.\n",
    "    n_z: integer, optional\n",
    "        The size of the grid in the z direction, defaults to 1\n",
    "    \"\"\"\n",
    "    vertices = np.arange(n_x * n_y * n_z).reshape((n_x, n_y, n_z))\n",
    "    edges_deep = np.vstack((vertices[:, :, :-1].ravel(),\n",
    "                            vertices[:, :, 1:].ravel()))\n",
    "    edges_right = np.vstack((vertices[:, :-1].ravel(),\n",
    "                             vertices[:, 1:].ravel()))\n",
    "    edges_down = np.vstack((vertices[:-1].ravel(), vertices[1:].ravel()))\n",
    "    edges = np.hstack((edges_deep, edges_right, edges_down))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _compute_altitude_3d(edges, img):\n",
    "    n_x, n_y, n_z = img.shape\n",
    "    gradient = np.abs(img[edges[0] // (n_y * n_z),\n",
    "                          (edges[0] % (n_y * n_z)) // n_z,\n",
    "                          (edges[0] % (n_y * n_z)) % n_z] -\n",
    "                          img[edges[1] // (n_y * n_z),\n",
    "                          (edges[1] % (n_y * n_z)) // n_z,\n",
    "                          (edges[1] % (n_y * n_z)) % n_z])\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_graph(image):\n",
    "    \n",
    "    dtype=None\n",
    "    image = np.atleast_3d(image)\n",
    "    n_x, n_y, n_z = image.shape\n",
    "    edges = _make_edges_3d(n_x, n_y, n_z)\n",
    "    weights = _compute_altitude_3d(edges, image)\n",
    "    diag = image.ravel()\n",
    "    n_voxels = diag.size\n",
    "    diag_idx = np.arange(n_voxels)\n",
    "    i_idx = np.hstack((edges[0], edges[1]))\n",
    "    j_idx = np.hstack((edges[1], edges[0]))\n",
    "    matrix = sparse.coo_matrix((np.hstack((weights, weights, diag)),\n",
    "                              (np.hstack((i_idx, diag_idx)),\n",
    "                               np.hstack((j_idx, diag_idx)))),\n",
    "                              (n_voxels, n_voxels),\n",
    "                              dtype=dtype)\n",
    "    graph = nx.from_scipy_sparse_matrix(matrix)\n",
    "    graph.remove_edges_from(graph.selfloop_edges())\n",
    "    \n",
    "    mapping = map_node(image)\n",
    "    values = get_altitude_map(image)\n",
    "    \n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    nx.set_node_attributes(graph,'value',values=values)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_altitude_map(img):\n",
    "    values = dict()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            values[(row,col)] = img[row,col][0]\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_node(img):\n",
    "    \n",
    "    assert isinstance(img, np.ndarray), \"Not an image\"\n",
    "    \n",
    "    mapping = dict()\n",
    "    \n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            mapping[row * img.shape[1] + col] = ((row), (col))\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_positions(img):\n",
    "    positions = dict()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            positions[(row,col)] = (col,row)\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_graph(img, graph, pixel_values=False, \n",
    "               figurename='graph.jpg'):\n",
    "    node_size = 500\n",
    "    node_color = 'b'\n",
    "    seed_color = 'r'\n",
    "    colors = [\"pink\",\"orange\",\"brown\",\"red\",\"green\",\n",
    "              \"orange\",\"beige\",\"turquoise\",\"blue\"]\n",
    "    \n",
    "    plt.figure(figsize=(img.shape[0],img.shape[1]))\n",
    "    \n",
    "    positions = get_image_positions(img)\n",
    "          \n",
    "    pos = nx.spring_layout(graph,pos=positions, fixed = graph.nodes())\n",
    "    labels = nx.get_edge_attributes(graph, 'weight')\n",
    "    \n",
    "\n",
    "    assigned_nodes = list((n for n in graph if graph.node[n]['seed'] != 'none'))\n",
    "    unassigned_nodes = list((n for n in graph if graph.node[n]['seed'] == 'none'))\n",
    "\n",
    "    \n",
    "    seeds = list((n for n in graph if graph.node[n]['type']=='seed'))\n",
    "    for x in range(len(seeds)):\n",
    "        nodes = list((n for n in graph if graph.node[n]['seed']==seeds[x]))\n",
    "        nx.draw_networkx_nodes(graph,pos,\n",
    "                       nodelist=nodes,\n",
    "                       node_color=colors[(x % (len(colors) - 1)) + 1],\n",
    "                       node_size=node_size,\n",
    "                   alpha=0.8)\n",
    "        nx.draw_networkx_nodes(graph,pos,\n",
    "                       nodelist=seeds,\n",
    "                       node_size=node_size,\n",
    "                   alpha=0.8, node_shape= 's')\n",
    "    \n",
    "    nx.draw_networkx_nodes(graph,pos,\n",
    "                       nodelist=unassigned_nodes,\n",
    "                       node_color=colors[0],\n",
    "                       node_size=node_size,\n",
    "                   alpha=0.8)\n",
    "\n",
    "        \n",
    "    \n",
    "    if pixel_values:\n",
    "        values = nx.get_node_attributes(graph,'value')\n",
    "        nx.draw_networkx_labels(graph,pos,labels=values)\n",
    "    else:\n",
    "        nx.draw_networkx_labels(graph,pos)\n",
    "\n",
    "    nx.draw_networkx_edge_labels(graph,pos,edge_labels=labels)\n",
    "    nx.draw_networkx_edges(graph,pos , width=5,edge_color='b')\n",
    "    \n",
    "    plt.savefig(figurename, dpi=100)\n",
    "    \n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    plt.savefig(figurename, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plant_seeds(graph, seeds):\n",
    "    \n",
    "    temp_graph = graph.copy()\n",
    "    \n",
    "    types_dict = dict()\n",
    "    assignment_dict = dict()\n",
    "    assignment_history = dict()\n",
    "\n",
    "    for x in temp_graph.nodes():\n",
    "        if x in seeds:\n",
    "            types_dict[x] = \"seed\"\n",
    "            assignment_dict[x] = x\n",
    "            assignment_history[x] = []\n",
    "        else:\n",
    "            types_dict[x] = \"node\"\n",
    "            assignment_dict[x] = 'none'\n",
    "            assignment_history[x] = []\n",
    "        \n",
    "            \n",
    "    nx.set_node_attributes(temp_graph, \"type\", types_dict)\n",
    "    nx.set_node_attributes(temp_graph, \"seed\", assignment_dict)\n",
    "    nx.set_node_attributes(temp_graph, \"path\", assignment_history)\n",
    "    \n",
    "    return temp_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_seeds(graph, n_seeds):\n",
    "    \n",
    "    seeds = []\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        seeds.append(random.choice(graph.nodes()))\n",
    "        \n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_graph_seed_assignments(graph):\n",
    "    assignments = dict()\n",
    "    for a, seed in enumerate(seeds):\n",
    "        nodes = list((n for n in graph if graph.node[n]['seed']==seeds[a]))\n",
    "        assignments.update(dict.fromkeys(nodes, a))\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spaced_colors(n):\n",
    "    max_value = 16581375 #255**3\n",
    "    interval = int(max_value / n)\n",
    "    colors = [hex(I)[2:].zfill(6) for I in range(0, max_value, interval)]\n",
    "    \n",
    "    return np.array([(int(i[:2], 16), int(i[2:4], 16), int(i[4:], 16)) for i in colors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projections(graph, seed, image):\n",
    "    '''This will output the relative labelings and save the RGB image to the relative labelings folder'''\n",
    "    \n",
    "    positions = get_image_positions(image)\n",
    "    assignments = get_graph_seed_assignments(graph)\n",
    "    \n",
    "    seeds = set(assignments.values())\n",
    "    n_seeds = len(seeds)\n",
    "    \n",
    "    seed_colors = get_spaced_colors(n_seeds)\n",
    "    \n",
    "    mask = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    \n",
    "    s = pd.Series(assignments)\n",
    "    s = s.values.reshape(image.shape)\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        a = s == x\n",
    "        if x == seed:\n",
    "            mask[a] = [0, 255, 0]\n",
    "        else:\n",
    "            mask[a] = [0, 0, 255]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prims_msf(G):\n",
    "    \n",
    "    MSF = nx.Graph()\n",
    "    nodes = G.nodes()\n",
    "    \n",
    "    s = filter(lambda (n, d): d['type'] == 'seed', G.nodes(data=True))\n",
    "    seeds = []\n",
    "    \n",
    "    edge_num = itertools.count(1)\n",
    "    num_edges = G.number_of_edges()\n",
    "    for x in s:\n",
    "        seeds.append(x[0])\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "\n",
    "    while nodes:\n",
    "        frontier = []\n",
    "        visited = []\n",
    "        for u in seeds:\n",
    "            nodes.remove(u)\n",
    "            visited.append(u)\n",
    "            \n",
    "            # Add seed to MSF\n",
    "            MSF.add_node(u, attr_dict=G.node[u])\n",
    "            \n",
    "            # Push all edges\n",
    "            for u, v in G.edges(u):\n",
    "                \n",
    "                #stdout.write(\"\\rCalculating edge {}/{}\".format(next(edge_num), num_edges))\n",
    "                #stdout.flush()\n",
    "               # percent_done = (next(edge_num) / num_edges) * 100\n",
    "               # if percent_done.is_integer():\n",
    "               #     print (\"%s percent done.\" % str(percent_done))\n",
    "                \n",
    "                push(frontier, (G[u][v].get('weight', 1), u, v))\n",
    "        \n",
    "        \n",
    "\n",
    "        while frontier:\n",
    "            W, u, v = pop(frontier)   \n",
    "\n",
    "            if v in visited:\n",
    "                continue\n",
    "            \n",
    "            # Assign the node\n",
    "            G.node[v]['seed'] = G.node[u]['seed']\n",
    "            \n",
    "            # Add node and edge to MSF\n",
    "            MSF.add_node(v,attr_dict=G.node[v])\n",
    "            MSF.add_edge(u,v,attr_dict=G.edge[u][v])\n",
    "            \n",
    "            #G.node[G.node[u]['seed']]['assignment history'] = G.node[G.node[u]['seed']]['assignment history'] + [v]       \n",
    "            \n",
    "            visited.append(v)\n",
    "            nodes.remove(v)\n",
    "            for v, w in G.edges(v):\n",
    "                if not w in visited:\n",
    "                    \n",
    "                    #stdout.write(\"\\rCalculating edge {}/{}\".format(next(edge_num), num_edges))\n",
    "                    #stdout.flush()\n",
    "                   # percent_done = (next(edge_num) / num_edges) * 100\n",
    "                    #if percent_done.is_integer():\n",
    "                    #    print (\"%s percent done.\" % str(percent_done))\n",
    "                    \n",
    "                    push(frontier, (G[v][w].get('weight', 1), v, w))\n",
    "    return MSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_of_view(master_image, center_pixel, crop_size):\n",
    "    \"\"\"Returns a crop of the master image centered on a specified pixel.\n",
    "    \n",
    "    Args:\n",
    "        master_image (numpy.ndarray): The master image to be cropped.\n",
    "        center_pixel (tuple): The pixel to be at the center of the crop.\n",
    "        window_size (tuple): The dimensions of the newly cropped image.\n",
    "        \n",
    "    Returns:\n",
    "        A cropped image of the master image with the specified pixel at the center.\n",
    "        \n",
    "    Examples:\n",
    "        fov = field_of_view(I, (0,0), (50,50))\"\"\"\n",
    "    \n",
    "    center = (center_pixel[0] + crop_size[0], center_pixel[1] + crop_size[1])\n",
    "\n",
    "    t_l = (center[0] - crop_size[0] // 2, center[1] - crop_size[1] // 2)\n",
    "    \n",
    "    return master_image[t_l[0]:t_l[0] + crop_size[0],t_l[1]:t_l[1] + crop_size[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assignment_mask(image, graph):\n",
    "    positions = get_image_positions(image)\n",
    "    assignments = get_graph_seed_assignments(graph)\n",
    "    \n",
    "    seeds = set(assignments.values())\n",
    "    n_seeds = len(seeds)\n",
    "    \n",
    "    seed_colors = get_spaced_colors(n_seeds)\n",
    "    \n",
    "    mask = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    \n",
    "    s = pd.Series(assignments)\n",
    "    s = s.values.reshape(image.shape)\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        a = s == x\n",
    "        mask[a] = seed_colors[x]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_arc_topographical_distance(path, graph):\n",
    "    \"\"\"Returns the max-arc topographical distance of a path in a graph.\n",
    "    \n",
    "    Args:\n",
    "        path (list): A list of tuples defining the path traversed in graph.\n",
    "        graph (networkx.classes.graph.Graph): The graph containing the path.\n",
    "        \n",
    "    Returns:\n",
    "        float: the max-arc topographical distance of path.\"\"\"\n",
    "\n",
    "    \n",
    "    G = graph.subgraph(path)\n",
    "    \n",
    "    distance = -np.infty\n",
    "    \n",
    "    for x, y in G.edges_iter():\n",
    "        altitude = G.edge[x][y]['weight']\n",
    "        if altitude > distance:\n",
    "            distance = altitude\n",
    "            edge = (x, y)\n",
    "            \n",
    "    return distance, edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_boundary_probabilities(img):\n",
    "    \"\"\"Returns boundary probabilites for an image\"\"\"\n",
    "    \n",
    "    #Make a placeholder for boundary probabilities coming in next iteration of pipeline\n",
    "    return np.random.rand(img.shape[0],img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _AsList(x):\n",
    "    return x if isinstance(x, (list, tuple)) else [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_altitudes(edges):\n",
    "    \"\"\"\n",
    "    Calculates a batch of edges.\n",
    "    \n",
    "    Args:\n",
    "        edges: A `Dictionary` where the keys are the edges that need their altitudes calculated,\n",
    "        and the values are the images that will be used to calculate the edges.\n",
    "        \n",
    "    Returns:\n",
    "        Returns a copy of the dictionary where the original values of the dictionary are replaced\n",
    "        with the altitudes of the edges.    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.stack(edges.values())\n",
    "\n",
    "    with sess.as_default():\n",
    "        altitudes = sess.run(f_static, feed_dict={image_placeholder: x,\n",
    "                                                 keras.backend.learning_phase(): 0})\n",
    "        \n",
    "    for i, (u, v) in enumerate(edges):\n",
    "        altitude = altitudes[i][0]\n",
    "        edges[(u, v)] = altitude\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prims_on_demand(G, image_dict):\n",
    "    \"\"\"\n",
    "    Creates a minimum spanning forest from give graph.\n",
    "    \n",
    "    Args:\n",
    "        G (Graph): Graph to use for minimum spanning forest.\n",
    "        image_dict (Dictionary): The dictionary of nodes used to calculate an altitude.\n",
    "        \n",
    "    Returns:\n",
    "        MSF (Graph): Minimum spanning forest.\n",
    "    \"\"\"\n",
    "    \n",
    "    MSF = nx.Graph()\n",
    "    nodes = G.nodes()\n",
    "    \n",
    "    s = filter(lambda (n, d): d['type'] == 'seed', G.nodes(data=True))\n",
    "    seeds = []\n",
    "    \n",
    "    for x in s:\n",
    "        seeds.append(x[0])\n",
    "        \n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    \n",
    "    while nodes:\n",
    "        frontier = []\n",
    "        visited = []\n",
    "        \n",
    "        for u in seeds:\n",
    "            nodes.remove(u)\n",
    "            visited.append(u)\n",
    "            \n",
    "            # Add seed to MSF\n",
    "            MSF.add_node(u, attr_dict=G.node[u])\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[u]['path'] = [u]\n",
    "            \n",
    "            uncalculated_edges = {}\n",
    "            \n",
    "            # Push all edges\n",
    "            for u, v in G.edges(u):\n",
    "                \n",
    "                # Fetch cropped image from dictionary and append it to the dictionary of edges to be\n",
    "                # calculated.\n",
    "                fov = image_dict[(v[0], v[1])]\n",
    "                uncalculated_edges[(u,v)] = fov\n",
    "                G.edge[u][v]['f_static_image'] = fov\n",
    "                G.edge[u][v]['f_dynamic_image'] = fov\n",
    "                \n",
    "            \n",
    "            uncalculated_edges = calculate_altitudes(uncalculated_edges)\n",
    "            \n",
    "            # Set the weight of the edges.\n",
    "            for i, (u, v) in enumerate(uncalculated_edges):\n",
    "                altitude = uncalculated_edges[(u, v)]\n",
    "                G.edge[u][v]['weight'] = altitude\n",
    "                push(frontier, (altitude, u, v))\n",
    "\n",
    "        while frontier:\n",
    "            W, u, v = pop(frontier)   \n",
    "            \n",
    "            if v in visited:\n",
    "                continue\n",
    "            \n",
    "            # Assign the node\n",
    "            G.node[v]['seed'] = G.node[u]['seed']\n",
    "            \n",
    "            # Add node and edge to MSF\n",
    "            MSF.add_node(v,attr_dict=G.node[v])\n",
    "            MSF.add_edge(u,v,attr_dict=G.edge[u][v])\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[v]['path'] = G.node[u]['path'] + [v]\n",
    "            \n",
    "            #G.node[G.node[u]['seed']]['assignment history'] = \\\n",
    "            #G.node[G.node[u]['seed']]['assignment history'] + [v]\n",
    "            \n",
    "            visited.append(v)\n",
    "            nodes.remove(v)\n",
    "            \n",
    "            uncalculated_edges = {}\n",
    "            \n",
    "            for v, w in G.edges(v):\n",
    "                if not w in visited:\n",
    "                    \n",
    "                    # Fetch cropped image from dictionary and append it to the dictionary of edges to be\n",
    "                    # calculated.\n",
    "                    fov = image_dict[(w[0], w[1])]\n",
    "                    uncalculated_edges[(v, w)] = fov\n",
    "                    G.edge[v][w]['f_static_image'] = fov\n",
    "                    G.edge[v][w]['f_dynamic_image'] = fov\n",
    "            \n",
    "            if len(uncalculated_edges) != 0:\n",
    "                uncalculated_edges = calculate_altitudes(uncalculated_edges)\n",
    "\n",
    "                for i, (v, w) in enumerate(uncalculated_edges):\n",
    "                    altitude = uncalculated_edges[(v, w)]\n",
    "                    G.edge[v][w]['weight'] = altitude\n",
    "                    push(frontier, (altitude, v, w))\n",
    "    \n",
    "    return MSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epoch_data(img_graph):\n",
    "    \"\"\"\n",
    "    Returns arrays containing edge calculation images and edge children count.\n",
    "    \n",
    "    Each edge weight corresponds to the same image used to calculate the edge.  For example,\n",
    "    if images[0] was used to compute edge ((0,0),(0,1)), then weights[0] would be the error\n",
    "    weight for that same edge.\n",
    "    \n",
    "    Args:\n",
    "        img_graph: (graph)\n",
    "    \n",
    "    Returns:\n",
    "        images (list): A list in which each element is the `ndarray` used to compute the\n",
    "        edge in the graph.\n",
    "        weights: (list): A list in which each element is the error weight for the edge.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    images = list()\n",
    "    weights = list()\n",
    "\n",
    "    for edge in img_graph.edges_iter():\n",
    "        try:\n",
    "            weights.append(img_graph.edge[edge[0]][edge[1]]['error_weight'])\n",
    "            images.append(img_graph.edge[edge[0]][edge[1]]['f_static_image'])\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    images = np.array(images)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    return images, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manually_check_loss(images, weights):\n",
    "    \"\"\"\n",
    "    Checks the loss of the given data.\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    with sess.as_default():\n",
    "        altitudes = sess.run(f_static, feed_dict={image_placeholder: images,\n",
    "                                                  keras.backend.learning_phase(): 0})\n",
    "        \n",
    "        loss = np.dot(weights, altitudes)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batches(x, y, max_batch_size=32):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        x: A numpy array of the input data\n",
    "        y: A numpy array of the output\n",
    "        max_batch_size: The maximum elements in each batch.\n",
    "\n",
    "    Returns: A list of batches.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    batches = math.ceil(x.shape[0] / max_batch_size)\n",
    "    x = np.array_split(x, batches)\n",
    "    y = np.array_split(y, batches)\n",
    "\n",
    "    return zip(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_deviation(ground_truth_path, shortest_path):\n",
    "    \"\"\"\n",
    "    Computes finds the edge where the ground truth path deviates from the shortest path.\n",
    "\n",
    "    Args:\n",
    "        ground_truth_path (list): The list of edges in the ground truth path.\n",
    "        shortest_path (list): The list of edges in the shortest path.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The first edge in which the two paths differ.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (ground_truth_node, shortest_path_node) in enumerate(zip(ground_truth_path, shortest_path)):\n",
    "        \n",
    "        if shortest_path_node != ground_truth_node:\n",
    "            return (ground_truth_path[i - 1], ground_truth_path[i])\n",
    "    else:\n",
    "        raise ValueError('No deviation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_false_cut(ground_truth_path, ground_truth_cuts, cut_edges):\n",
    "    \"\"\"\n",
    "    Finds the first false cut edge of a ground truth path.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        ground_truth_path (list): A list of nodes representing the path from the seed to the node.\n",
    "        ground_truth_cuts (list): A list of ground truth cut edges. \n",
    "        cut_edges (list): A list of cut edges from the minimum spanning forest.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The first edge in the ground truth path that is in the list of cut edges, but not in\n",
    "        in the list of ground truth edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, node in enumerate(ground_truth_path):\n",
    "        try:\n",
    "            edge = (ground_truth_path[i], ground_truth_path[i + 1])\n",
    "            if edge in cut_edges or tuple(reversed(edge)) in cut_edges:\n",
    "                if edge not in ground_truth_cuts or tuple(reversed(edge)) not in ground_truth_cuts:\n",
    "                    return edge\n",
    "\n",
    "        except IndexError:\n",
    "            print \"Something went wrong.\"\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_root_edge(node, msf, constrained_msf, cut_edges, ground_truth_cuts, edge_error_weights):\n",
    "    \"\"\"\n",
    "    Finds the root error edges for a node and inserts them into the dictionary.\n",
    "    \n",
    "    Args:\n",
    "        node (tuple): The node to find the root error edges for.\n",
    "        msf (Graph): The MSF used to find the shortest path.\n",
    "        constrained_msf (Graph): The constrained MSF used to find the ground truth path.\n",
    "        cut_edges (list): A list of tuples representing the cuts for the graph.\n",
    "        edge_error_weights (dictionary): The dictionary that holds all of the weights for the root\n",
    "        error edges.        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get assigned seeds for MSF and constrained MSF.\n",
    "    assigned_seed = msf.node[node]['seed']\n",
    "    ground_truth_seed = constrained_msf.node[node]['seed']\n",
    "\n",
    "    # Get the path from seed to node\n",
    "    shortest_path = next(nx.all_simple_paths(msf, assigned_seed, node))\n",
    "    ground_truth_path = next(nx.all_simple_paths(constrained_msf, ground_truth_seed, node))\n",
    "\n",
    "    # Get the distances from the seed to the node.\n",
    "    shortest_path_distance, shortest_distance_edge = max_arc_topographical_distance(shortest_path,\n",
    "                                                                                    msf)\n",
    "    ground_truth_path_distance, ground_truth_distance_edge = \\\n",
    "                                max_arc_topographical_distance(ground_truth_path,\n",
    "                                                               constrained_msf)\n",
    "\n",
    "\n",
    "    # Check is the ground truth path and the shortest path are equivalent.  If so, \n",
    "    #  then the node is correct, if not, then the node is incorrect.  \n",
    "    if shortest_path != ground_truth_path:\n",
    "        # The node is incorrect. \n",
    "\n",
    "        # Compute the root edge to increase (p(w)).\n",
    "        root_missing_cut_edge = find_missing_cut(shortest_path, ground_truth_cuts, \n",
    "                                                 cut_edges)\n",
    "\n",
    "\n",
    "        # Increment the number of children for the root edge.\n",
    "        try:\n",
    "            edge_error_weights[root_missing_cut_edge]\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            edge_error_weights[root_missing_cut_edge] = 0\n",
    "        finally:\n",
    "\n",
    "            edge_error_weights[root_missing_cut_edge] = \\\n",
    "            edge_error_weights[root_missing_cut_edge] - 1\n",
    "\n",
    "        # Compute the root edge to decrease.\n",
    "        if assigned_seed != ground_truth_seed:\n",
    "            root_false_cut_edge = find_first_false_cut(ground_truth_path,\n",
    "                                                       ground_truth_cuts,\n",
    "                                                       cut_edges)\n",
    "        else:\n",
    "            root_false_cut_edge = find_deviation(ground_truth_path, shortest_path)   \n",
    "\n",
    "        try:\n",
    "            edge_error_weights[root_false_cut_edge]\n",
    "        except KeyError:\n",
    "            edge_error_weights[root_false_cut_edge] = 0\n",
    "        finally:\n",
    "            edge_error_weights[root_false_cut_edge] = \\\n",
    "            edge_error_weights[root_false_cut_edge] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_root_error_edge_children(msf, constrained_msf, cut_edges, ground_truth_cuts):\n",
    "    \"\"\"\n",
    "    Computes the root error edges used for a single training epoch of the system.\n",
    "\n",
    "    This function will prepare the weight function and the altitude prediction used for the loss.\n",
    "    The approach taken here is for every node in the graph, check if the node satisfies a failure \n",
    "    condition. If so, then add or subtract to the root error edge children.           \n",
    "\n",
    "    By construction of the MSF, the shortest path and the ground truth path are equal\n",
    "    for all nodes.  Conversely, they differ for incorrect nodes, causing the gound truth\n",
    "    path distance to exceed the shortest path distance.\n",
    "\n",
    "    TODO:\n",
    "        Write function to fetch root error false cuts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize edge error weights dictionary.\n",
    "    edge_error_weights = dict()\n",
    "    \n",
    "    # Create a list of nodes and iterate through them.\n",
    "    nodes = list((n for n in msf if msf.node[n]['type']=='node'))\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    # Here multithreading is used to speed up root error edge computation.  Each thread \n",
    "    # computes the root error edges for a node.\n",
    "    threads = []\n",
    "    for i, node in enumerate(nodes):\n",
    "        \n",
    "        #stdout.write(\"\\rChecking Node {}/{}\".format(i, len(nodes)))\n",
    "        #stdout.flush()\n",
    "        \n",
    "        thread = threading.Thread(target=find_root_edge, args=[node, msf, constrained_msf,\n",
    "                                                              cut_edges, ground_truth_cuts,\n",
    "                                                              edge_error_weights])\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    # Join threads\n",
    "    [thread.join() for thread in threads]\n",
    "    \n",
    "    # Compute correct nodes and accuracy.\n",
    "    correct_nodes = num_nodes - sum(map(abs, edge_error_weights.values()))\n",
    "                \n",
    "    accuracy = correct_nodes / num_nodes\n",
    "    print \"\\nCorrect nodes: {}/{}\".format(correct_nodes, num_nodes) \n",
    "    print \"Accuracy: \", accuracy\n",
    "\n",
    "    return edge_error_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_boundary_line(image, graph, figurename=\"graph.jpg\"):\n",
    "    \"\"\"\n",
    "    Draws the segmentation boundary line on the image for the given graph.\n",
    "    \n",
    "    Args:\n",
    "        graph: The graph to use to compute the boundary lines.\n",
    "        figurename: The name of the image to be saved to the current working directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    boundary_nodes = list()\n",
    "    \n",
    "    seeds = list((n for n in graph if graph.node[n]['type']=='seed'))\n",
    "    boundary_nodes.extend(seeds)\n",
    "    \n",
    "    for edge in graph.edges_iter():            \n",
    "        if graph.node[edge[0]]['seed'] is not graph.node[edge[1]]['seed']:\n",
    "            boundary_nodes.extend([edge[0], edge[1]])\n",
    "            \n",
    "    sub_graph = graph.subgraph(boundary_nodes)\n",
    "    view_graph(image, sub_graph, figurename=figurename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_missing_cut(shortest_path, ground_truth_cuts, cut_edges):\n",
    "    \"\"\"\n",
    "    Computes the root error missing cut of a shortest path.\n",
    "\n",
    "    Every incorrect shortest path has at least one erroneous cut edge.  The first such\n",
    "    edge shall be called the path's root error edge p(w) and is always a missing cut.\n",
    "\n",
    "    Args:\n",
    "        shortest_path (list): The list of edges in the shortest path.\n",
    "        ground_truth_cuts (list): The list ground truth cuts for the ground truth segmentation.\n",
    "        cut_edges (list): The list of cut edges from the current segmentation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The first erroneous cut edge in the shortest path.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, node in enumerate(shortest_path):\n",
    "        try:\n",
    "            edge = (shortest_path[i], shortest_path[i + 1])\n",
    "            if edge in ground_truth_cuts or tuple(reversed(edge)) in ground_truth_cuts:\n",
    "                if edge not in cut_edges and tuple(reversed(edge)) not in cut_edges:\n",
    "                    return edge\n",
    "\n",
    "        except IndexError:\n",
    "            print \"Something went wrong.\"\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Watershed:\n",
    "    \n",
    "    def __init__(self, window_size=(32,32)):\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def fit(self, images, ground_truth_images, epochs=16, batch_size=32, verbose=False):\n",
    "        \"\"\"\n",
    "        Fits the model given an image or set of images.\n",
    "        \n",
    "        Args:\n",
    "            images: A `numpy.ndarray` or list of arrays to be used to fit the model.\n",
    "            ground_truth_images: A `numpy.ndarray` or list of arrays to be used to fit the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.verbose=verbose\n",
    "        self.epochs = epochs\n",
    "        self.images = _AsList(images)\n",
    "        self.ground_truth_images = _AsList(ground_truth_images)\n",
    "        \n",
    "        for image, ground_truth_image in zip(self.images, self.ground_truth_images):\n",
    "            self.image = image\n",
    "            self.ground_truth_image = ground_truth_image\n",
    "            self._train_single()\n",
    "        \n",
    "    def _train_single(self):\n",
    "        \"\"\"\n",
    "        Trains the model on a single image. Training is composed of two steps. First the image is\n",
    "        segmented. Second, the model is updated. Before the model is trained, the ground truth\n",
    "        cut edges are calculated.\n",
    "        \"\"\"\n",
    "        \n",
    "        print \"Computing ground truth cuts.\"\n",
    "        \n",
    "        start = time.time()\n",
    "        self.ground_truth_cuts = self._compute_ground_truth_cuts(self.ground_truth_image,\n",
    "                                                                 self.seeds)\n",
    "        end = time.time()\n",
    "        \n",
    "        print (\"\\nTime: %f\" % (end - start))\n",
    "        \n",
    "        loss_timeline = list()\n",
    "        \n",
    "        for i in xrange(self.epochs):\n",
    "            self.current_epoch = i + 1\n",
    "            print \"\\n===========\"\n",
    "            print \"Epoch \", self.current_epoch\n",
    "            print \"===========\"\n",
    "            \n",
    "            print \"Computing the MSF\"\n",
    "            start = time.time()\n",
    "            segmentation = self.segment(self.image)\n",
    "            end = time.time()\n",
    "            print \"Done in {} seconds\".format(end - start)\n",
    "            \n",
    "            if self.verbose:\n",
    "                filename = \"training_images/epoch_{}.jpg\".format(self.current_epoch)\n",
    "                cv2.imwrite(filename, segmentation)\n",
    "            \n",
    "            loss_val = self._training_epoch()\n",
    "            loss_timeline.append(loss_val)\n",
    "            plt.plot(loss_timeline)\n",
    "            plt.savefig(\"training_images/Loss.jpg\")\n",
    "            \n",
    "            print \"Loss: \", loss_val\n",
    "        \n",
    "\n",
    "    def segment(self, image):\n",
    "        \"\"\"\n",
    "        Segments image.\n",
    "        \n",
    "        TODO:\n",
    "            Create and return segmented image.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._prepare_input_images()\n",
    "        \n",
    "        # Translate image to 4 connected grid graph.\n",
    "        self.image_graph = img_to_graph(image)\n",
    "            \n",
    "        # Plant seeds.\n",
    "        self.image_graph = plant_seeds(self.image_graph, self.seeds)\n",
    "        \n",
    "        # Compute image MSF.\n",
    "        self.image_msf =  prims_on_demand(self.image_graph, self.input_images)\n",
    "\n",
    "        # Compute cut edges\n",
    "        self.cut_edges = []\n",
    "        \n",
    "        [self.cut_edges.append(e) if self.image_msf.node[e[0]]['seed']\\\n",
    "        is not self.image_msf.node[e[1]]['seed'] else '' for e in\\\n",
    "        self.image_graph.edges_iter()]\n",
    "            \n",
    "        return assignment_mask(image, self.image_graph)\n",
    "        \n",
    "    def _training_epoch(self):\n",
    "        \"\"\"\n",
    "        This is the training epoch for each image.  The approach taken here is to first \n",
    "        create the constrained msf with the ground truth cut edges, then compute\n",
    "        the root error edges, afterwards compute and apply the updates for the model parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the constrained MSF.\n",
    "        print \"Compute constrained MSF\"\n",
    "        start = time.time()\n",
    "        self.constrained_msf = self._compute_constrained_msf()\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        \n",
    "        print \"2. Identifying root edges and loss.\"\n",
    "        start = time.time()\n",
    "        edge_error_weights = compute_root_error_edge_children(self.image_msf, self.constrained_msf,\n",
    "                                                                 self.cut_edges, self.ground_truth_cuts)\n",
    "        \n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        \n",
    "        nx.set_edge_attributes(self.image_graph, 'error_weight', edge_error_weights)\n",
    "        \n",
    "        # Fetch the training data from the image graph.\n",
    "        images, weights = epoch_data(self.image_graph)\n",
    "        \n",
    "        # Split data into batches.\n",
    "        batches = create_batches(images, weights)\n",
    "        \n",
    "        # Compute loss.\n",
    "        print \"Computing Loss\"\n",
    "        start = time.time()\n",
    "        with sess.as_default():\n",
    "            loss_val = sess.run(loss, feed_dict={image_placeholder: images,\n",
    "                                                 gradient_weights: [weights],\n",
    "                                                 keras.backend.learning_phase(): 0})\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        loss_val = loss_val[0][0]\n",
    "            \n",
    "        # Update parameters\n",
    "        print \"Updating Parameters.\"\n",
    "        start = time.time()\n",
    "        with sess.as_default():\n",
    "            \n",
    "            # Zero out gradient accumulator.\n",
    "            sess.run(zero_ops)\n",
    "            \n",
    "            # Accumulate gradients.\n",
    "            for batch in batches:\n",
    "                sess.run(accum_ops, feed_dict={image_placeholder: batch[0],\n",
    "                                               gradient_weights: [batch[1]],\n",
    "                                               keras.backend.learning_phase(): 0})\n",
    "            \n",
    "            sess.run(train_step)\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "            \n",
    "        gc.collect()\n",
    "            \n",
    "        return loss_val\n",
    "    \n",
    "    \n",
    "    def _compute_ground_truth_cuts(self, ground_truth_image, seeds):\n",
    "        \"\"\"\n",
    "        Computes the ground truth cuts of the given image.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth_image (ndarray): The image used to create the ground truth cuts.\n",
    "            seeds (list): A list of seeds to start watershed.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of ground truth cut edges.\n",
    "        \"\"\"\n",
    "        \n",
    "        ground_truth_graph = img_to_graph(ground_truth_image)\n",
    "        ground_truth_graph = plant_seeds(ground_truth_graph, self.seeds)\n",
    "        ground_truth_msf = prims_msf(ground_truth_graph)\n",
    "        \n",
    "        # Compute the ground truth cut edges\n",
    "        ground_truth_cuts = []\n",
    "        [ground_truth_cuts.append(e) if ground_truth_msf.node[e[0]]['seed']\\\n",
    "                 is not ground_truth_msf.node[e[1]]['seed'] else '' for e in\\\n",
    "                 ground_truth_graph.edges_iter()]\n",
    "        \n",
    "        ground_truth_segmentation = assignment_mask(self.image, ground_truth_graph)\n",
    "        filename = \"training_images/ground_truth_segmentation.jpg\"\n",
    "        cv2.imwrite(filename, ground_truth_segmentation)\n",
    "        \n",
    "        return ground_truth_cuts\n",
    "            \n",
    "\n",
    "    def _prepare_input_images(self):\n",
    "        \"\"\"\n",
    "        Preprocess images to be used in the prediction of the edges.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.padded_image = np.pad(self.image,(self.window_size [0],self.window_size [1]),'reflect')\n",
    "        \n",
    "        #boundary_probabilities = get_boundary_probabilities(self.padded_image)\n",
    "        boundary_probabilities = np.pad(self.ground_truth_image,(self.window_size [0],self.window_size [1]),'reflect')\n",
    "\n",
    "        #Augment the image with boundary probabilities\n",
    "        self.augmented_image = np.dstack((self.padded_image, boundary_probabilities))\n",
    "\n",
    "        # Get input images\n",
    "        self.input_images = dict()\n",
    "\n",
    "        for x in range(self.image.shape[0]):\n",
    "            for y in range(self.image.shape[1]):\n",
    "                node = (x, y)\n",
    "                self.input_images[node] = field_of_view(self.augmented_image, node, self.window_size)\n",
    "\n",
    "        \n",
    "    def _compute_constrained_msf(self):\n",
    "        \"\"\"\n",
    "        Returns the constained msf.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_cuts = self.image_graph.copy()\n",
    "        self.img_cuts.remove_edges_from(self.ground_truth_cuts)\n",
    "        return prims_msf(self.img_cuts)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def ground_truth_cuts(self):\n",
    "        return self.ground_truth_cuts\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def cut_edges(self):\n",
    "        return self.cut_edges\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def image_graph(self):\n",
    "        return self.image_graph\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def seeds(self):\n",
    "        return self.seeds\n",
    "    \n",
    "    \n",
    "    @seeds.setter\n",
    "    def seeds(self, seeds):\n",
    "        self.seeds = seeds\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def window_size(self):\n",
    "        return self.window_size\n",
    "    \n",
    "    @property\n",
    "    def image_dict(self):\n",
    "        return self.image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS THE START OF THE COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set image size\n",
    "image_tl = (0, 0)\n",
    "image_size = (50, 50)\n",
    "window_size = (15, 15)\n",
    "\n",
    "#import Images\n",
    "img = cv2.imread('1O.jpg', 0)\n",
    "gt = cv2.imread('1G.jpg', 0)\n",
    "\n",
    "#resize\n",
    "img = img[image_tl[0]:image_tl[0] + image_size[0],\n",
    "          image_tl[1]:image_tl[1] + image_size[1]]\n",
    "gt = gt[image_tl[0]:image_tl[0] + image_size[0],\n",
    "        image_tl[1]:image_tl[1] + image_size[1]]\n",
    "\n",
    "#set type\n",
    "img = img.astype(np.int16)\n",
    "gt = gt.astype(np.int16)\n",
    "\n",
    "# Save image\n",
    "plt.imsave(\"training_images/image\", cv2.resize(img, (1000,1000)), cmap='gray')\n",
    "plt.clf()\n",
    "\n",
    "# Import seeds\n",
    "seeds = []\n",
    "f = open(\"seeds1G.txt\", 'r')\n",
    "for line in f:\n",
    "    x = int(float(re.split(' ', line)[0]))\n",
    "    y = int(float(re.split(' ', line)[1]))\n",
    "    seed = (x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "    if x >= image_tl[0] and x <= image_tl[0] + image_size[0]:\n",
    "        if y >= image_tl[1] and y <= image_tl[1] + image_size[1]:\n",
    "            x = x - image_tl[0]\n",
    "            y = y - image_tl[1]\n",
    "            seed = (x, y)\n",
    "            seeds.append(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This placeholder will contain the input images\n",
    "image_placeholder = tf.placeholder(tf.float32, shape=(None, window_size[0], window_size[0], 2))\n",
    "\n",
    "# Create model\n",
    "m = keras.layers.Conv2D(16, 5, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (image_placeholder)\n",
    "m = keras.layers.Conv2D(16, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(32, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=2) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(32, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=4) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(64, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=8) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(64, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=16) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(128, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Flatten()(m)\n",
    "m = keras.layers.Dense(1024, activation='relu')(m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Dense(1, activation='elu')(m)\n",
    "f_static = keras.layers.BatchNormalization() (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This placeholder will hold the root error edge values.\n",
    "gradient_weights = tf.placeholder(tf.float32, shape=(1, None))\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.000001)\n",
    "\n",
    "tvs = tf.trainable_variables()\n",
    "\n",
    "loss = tf.matmul(gradient_weights, f_static)\n",
    "\n",
    "# Accumulate gradients of predictions with respect to the parameters.\n",
    "accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        \n",
    "zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "gvs = opt.compute_gradients(loss, tvs)\n",
    "accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "\n",
    "# Apply gradients\n",
    "train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])\n",
    "\n",
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = Watershed(window_size=window_size)\n",
    "\n",
    "w.seeds = seeds\n",
    "\n",
    "w.fit(img, gt, epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.image_graph.node[(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set image size\n",
    "image_tl = (300,300)\n",
    "\n",
    "#import Images\n",
    "img = cv2.imread('1O.jpg', 0)\n",
    "gt = cv2.imread('1G.jpg', 0)\n",
    "\n",
    "#resize\n",
    "img = img[image_tl[0]:image_tl[0] + image_size[0],\n",
    "          image_tl[1]:image_tl[1] + image_size[1]]\n",
    "gt = gt[image_tl[0]:image_tl[0] + image_size[0],\n",
    "        image_tl[1]:image_tl[1] + image_size[1]]\n",
    "\n",
    "#set type\n",
    "img = img.astype(np.int16)\n",
    "gt = gt.astype(np.int16)\n",
    "\n",
    "# Save image\n",
    "plt.imsave(\"image\", cv2.resize(img, (1000,1000)), cmap='gray')\n",
    "plt.clf()\n",
    "\n",
    "# Import seeds\n",
    "seeds = []\n",
    "f = open(\"seeds1G.txt\", 'r')\n",
    "for line in f:\n",
    "    x = int(float(re.split(' ', line)[0]))\n",
    "    y = int(float(re.split(' ', line)[1]))\n",
    "    seed = (x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "    if x >= image_tl[0] and x <= image_tl[0] + image_size[0]:\n",
    "        if y >= image_tl[1] and y <= image_tl[1] + image_size[1]:\n",
    "            x = x - image_tl[0]\n",
    "            y = y - image_tl[1]\n",
    "            seed = (x, y)\n",
    "            seeds.append(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.seeds = seeds\n",
    "\n",
    "segmentation = w.segment(img)\n",
    "\n",
    "\n",
    "filename = \"test.jpg\"\n",
    "cv2.imwrite(filename, segmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
