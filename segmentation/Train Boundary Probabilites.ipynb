{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from models import BachNet\n",
    "from utils import preprocessing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bach = BachNet.BachNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"data/train/input/\"\n",
    "path_to_original_images = \"original/\"\n",
    "path_to_gt_images = \"gt/\"\n",
    "\n",
    "gt_tag = \"gt\"\n",
    "\n",
    "receptive_field_shape = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Images\n",
      "\r",
      "Progress: 0.00% || 0/98\r",
      "Progress: 0.01% || 1/98\r",
      "Progress: 0.02% || 2/98\r",
      "Progress: 0.03% || 3/98\r",
      "Progress: 0.04% || 4/98\r",
      "Progress: 0.05% || 5/98\r",
      "Progress: 0.06% || 6/98\r",
      "Progress: 0.07% || 7/98\r",
      "Progress: 0.08% || 8/98\r",
      "Progress: 0.09% || 9/98\r",
      "Progress: 0.10% || 10/98\r",
      "Progress: 0.11% || 11/98\r",
      "Progress: 0.12% || 12/98\r",
      "Progress: 0.13% || 13/98\r",
      "Progress: 0.14% || 14/98\r",
      "Progress: 0.15% || 15/98\r",
      "Progress: 0.16% || 16/98\r",
      "Progress: 0.17% || 17/98\r",
      "Progress: 0.18% || 18/98\r",
      "Progress: 0.19% || 19/98\r",
      "Progress: 0.20% || 20/98\r",
      "Progress: 0.21% || 21/98\r",
      "Progress: 0.22% || 22/98\r",
      "Progress: 0.23% || 23/98\r",
      "Progress: 0.24% || 24/98\r",
      "Progress: 0.26% || 25/98\r",
      "Progress: 0.27% || 26/98\r",
      "Progress: 0.28% || 27/98\r",
      "Progress: 0.29% || 28/98\r",
      "Progress: 0.30% || 29/98\r",
      "Progress: 0.31% || 30/98\r",
      "Progress: 0.32% || 31/98\r",
      "Progress: 0.33% || 32/98\r",
      "Progress: 0.34% || 33/98\r",
      "Progress: 0.35% || 34/98\r",
      "Progress: 0.36% || 35/98\r",
      "Progress: 0.37% || 36/98\r",
      "Progress: 0.38% || 37/98\r",
      "Progress: 0.39% || 38/98\r",
      "Progress: 0.40% || 39/98\r",
      "Progress: 0.41% || 40/98\r",
      "Progress: 0.42% || 41/98\r",
      "Progress: 0.43% || 42/98\r",
      "Progress: 0.44% || 43/98\r",
      "Progress: 0.45% || 44/98\r",
      "Progress: 0.46% || 45/98\r",
      "Progress: 0.47% || 46/98\r",
      "Progress: 0.48% || 47/98\r",
      "Progress: 0.49% || 48/98\r",
      "Progress: 0.50% || 49/98\r",
      "Progress: 0.51% || 50/98\r",
      "Progress: 0.52% || 51/98\r",
      "Progress: 0.53% || 52/98\r",
      "Progress: 0.54% || 53/98\r",
      "Progress: 0.55% || 54/98\r",
      "Progress: 0.56% || 55/98\r",
      "Progress: 0.57% || 56/98\r",
      "Progress: 0.58% || 57/98\r",
      "Progress: 0.59% || 58/98\r",
      "Progress: 0.60% || 59/98\r",
      "Progress: 0.61% || 60/98\r",
      "Progress: 0.62% || 61/98\r",
      "Progress: 0.63% || 62/98\r",
      "Progress: 0.64% || 63/98\r",
      "Progress: 0.65% || 64/98\r",
      "Progress: 0.66% || 65/98\r",
      "Progress: 0.67% || 66/98\r",
      "Progress: 0.68% || 67/98\r",
      "Progress: 0.69% || 68/98\r",
      "Progress: 0.70% || 69/98\r",
      "Progress: 0.71% || 70/98\r",
      "Progress: 0.72% || 71/98\r",
      "Progress: 0.73% || 72/98\r",
      "Progress: 0.74% || 73/98\r",
      "Progress: 0.76% || 74/98\r",
      "Progress: 0.77% || 75/98\r",
      "Progress: 0.78% || 76/98\r",
      "Progress: 0.79% || 77/98\r",
      "Progress: 0.80% || 78/98\r",
      "Progress: 0.81% || 79/98\r",
      "Progress: 0.82% || 80/98\r",
      "Progress: 0.83% || 81/98\r",
      "Progress: 0.84% || 82/98\r",
      "Progress: 0.85% || 83/98\r",
      "Progress: 0.86% || 84/98\r",
      "Progress: 0.87% || 85/98\r",
      "Progress: 0.88% || 86/98\r",
      "Progress: 0.89% || 87/98\r",
      "Progress: 0.90% || 88/98\r",
      "Progress: 0.91% || 89/98\r",
      "Progress: 0.92% || 90/98\r",
      "Progress: 0.93% || 91/98\r",
      "Progress: 0.94% || 92/98\r",
      "Progress: 0.95% || 93/98\r",
      "Progress: 0.96% || 94/98\r",
      "Progress: 0.97% || 95/98\r",
      "Progress: 0.98% || 96/98\r",
      "Progress: 0.99% || 97/98\r",
      "Progress: Done! || 98/98"
     ]
    }
   ],
   "source": [
    "print(\"Loading Images\")\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "files = os.listdir(train_path)\n",
    "\n",
    "for i, filename in enumerate(files):\n",
    "    \n",
    "    sys.stdout.write(\"\\rProgress: %.2f%% || %d/%d\" % (i / len(files),\n",
    "                                                      i,\n",
    "                                                      len(files)))\n",
    "    \n",
    "    \n",
    "    f_name, ext = os.path.splitext(filename)\n",
    "    \n",
    "    if gt_tag in f_name.split(\"_\"):\n",
    "        continue\n",
    "        \n",
    "    gt_filename = f_name + \"_\" + gt_tag\n",
    "    \n",
    "    gt_path = os.path.join(train_path, (gt_filename + ext))\n",
    "        \n",
    "    if not os.path.isfile(gt_path):\n",
    "        continue\n",
    "        \n",
    "    foldername = \"data/train/chopin/\" + f_name\n",
    "        \n",
    "    image_path = os.path.join(train_path, filename)\n",
    "        \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    \n",
    "    x = preprocessing_utils.prepare_input_images(img, width=receptive_field_shape[0],\n",
    "                                                 height=receptive_field_shape[1])\n",
    "    \n",
    "    X.append(x)\n",
    "\n",
    "    gt = cv2.imread(gt_path, 0)\n",
    "    y = np.zeros_like(gt)\n",
    "    y[gt == 255] = 1\n",
    "    y = y.flatten()\n",
    "    \n",
    "    Y.append(y)\n",
    "    \n",
    "X = np.concatenate(X)\n",
    "Y = np.concatenate(Y)\n",
    "\n",
    "sys.stdout.write(\"\\rProgress: Done! || %d/%d\" % (len(files),\n",
    "                                                len(files)))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8b1b199d10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b1b26b650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50176, 12, 12, 1) (50176,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bach.build(receptive_field_shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.3597 - acc: 0.8603     \n",
      "Epoch 2/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2959 - acc: 0.8809     \n",
      "Epoch 3/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2816 - acc: 0.8873     \n",
      "Epoch 4/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2734 - acc: 0.8893     \n",
      "Epoch 5/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2635 - acc: 0.8936     \n",
      "Epoch 6/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2597 - acc: 0.8949     \n",
      "Epoch 7/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2543 - acc: 0.8968     \n",
      "Epoch 8/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2478 - acc: 0.9010     \n",
      "Epoch 9/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2444 - acc: 0.9009     \n",
      "Epoch 10/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2391 - acc: 0.9026     \n",
      "Epoch 11/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2328 - acc: 0.9060     \n",
      "Epoch 12/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2294 - acc: 0.9069     \n",
      "Epoch 13/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2267 - acc: 0.9082     \n",
      "Epoch 14/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2248 - acc: 0.9074     \n",
      "Epoch 15/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2204 - acc: 0.9102     \n",
      "Epoch 16/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2169 - acc: 0.9119     \n",
      "Epoch 17/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2105 - acc: 0.9138     \n",
      "Epoch 18/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2065 - acc: 0.9149     \n",
      "Epoch 19/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2062 - acc: 0.9159     \n",
      "Epoch 20/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.2009 - acc: 0.9173     \n",
      "Epoch 21/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1994 - acc: 0.9171     \n",
      "Epoch 22/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1929 - acc: 0.9205     \n",
      "Epoch 23/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1907 - acc: 0.9195     \n",
      "Epoch 24/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1891 - acc: 0.9211     \n",
      "Epoch 25/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1812 - acc: 0.9247     \n",
      "Epoch 26/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1805 - acc: 0.9242     \n",
      "Epoch 27/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1787 - acc: 0.9247     \n",
      "Epoch 28/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1748 - acc: 0.9263     \n",
      "Epoch 29/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1710 - acc: 0.9274     \n",
      "Epoch 30/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1687 - acc: 0.9299     \n",
      "Epoch 31/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1668 - acc: 0.9288     \n",
      "Epoch 32/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1643 - acc: 0.9315     \n",
      "Epoch 33/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1623 - acc: 0.9305     \n",
      "Epoch 34/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1617 - acc: 0.9310     \n",
      "Epoch 35/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1596 - acc: 0.9310     \n",
      "Epoch 36/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1543 - acc: 0.9323     \n",
      "Epoch 37/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1550 - acc: 0.9331     \n",
      "Epoch 38/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1512 - acc: 0.9343     \n",
      "Epoch 39/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1488 - acc: 0.9353     \n",
      "Epoch 40/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1492 - acc: 0.9353     \n",
      "Epoch 41/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1500 - acc: 0.9343     \n",
      "Epoch 42/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1458 - acc: 0.9371     \n",
      "Epoch 43/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1479 - acc: 0.9353     \n",
      "Epoch 44/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1430 - acc: 0.9366     \n",
      "Epoch 45/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1410 - acc: 0.9387     \n",
      "Epoch 46/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1396 - acc: 0.9378     \n",
      "Epoch 47/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1409 - acc: 0.9370     \n",
      "Epoch 48/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1400 - acc: 0.9377     \n",
      "Epoch 49/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1388 - acc: 0.9389     \n",
      "Epoch 50/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1388 - acc: 0.9385     \n",
      "Epoch 51/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1359 - acc: 0.9389     \n",
      "Epoch 52/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1368 - acc: 0.9390     \n",
      "Epoch 53/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1340 - acc: 0.9388     \n",
      "Epoch 54/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1351 - acc: 0.9391     \n",
      "Epoch 55/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1312 - acc: 0.9405     \n",
      "Epoch 56/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1317 - acc: 0.9404     \n",
      "Epoch 57/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1311 - acc: 0.9410     \n",
      "Epoch 58/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1311 - acc: 0.9409     \n",
      "Epoch 59/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1274 - acc: 0.9418     \n",
      "Epoch 60/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1272 - acc: 0.9427     \n",
      "Epoch 61/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1290 - acc: 0.9409     \n",
      "Epoch 62/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1256 - acc: 0.9427     \n",
      "Epoch 63/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1251 - acc: 0.9437     \n",
      "Epoch 64/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1319 - acc: 0.9390     \n",
      "Epoch 65/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1272 - acc: 0.9413     \n",
      "Epoch 66/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1279 - acc: 0.9416     \n",
      "Epoch 67/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1291 - acc: 0.9407     \n",
      "Epoch 68/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1250 - acc: 0.9425     \n",
      "Epoch 69/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1240 - acc: 0.9417     \n",
      "Epoch 70/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1236 - acc: 0.9439     \n",
      "Epoch 71/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1248 - acc: 0.9426     \n",
      "Epoch 72/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1228 - acc: 0.9439     \n",
      "Epoch 73/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1245 - acc: 0.9431     \n",
      "Epoch 74/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1216 - acc: 0.9443     \n",
      "Epoch 75/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1209 - acc: 0.9443     \n",
      "Epoch 76/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1212 - acc: 0.9444     \n",
      "Epoch 77/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1243 - acc: 0.9427     \n",
      "Epoch 78/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1194 - acc: 0.9456     \n",
      "Epoch 79/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1188 - acc: 0.9449     \n",
      "Epoch 80/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1187 - acc: 0.9457     \n",
      "Epoch 81/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1195 - acc: 0.9445     \n",
      "Epoch 82/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1184 - acc: 0.9453     \n",
      "Epoch 83/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1205 - acc: 0.9450     \n",
      "Epoch 84/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1198 - acc: 0.9445     \n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50176/50176 [==============================] - 1s - loss: 0.1193 - acc: 0.9455     \n",
      "Epoch 86/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1201 - acc: 0.9450     \n",
      "Epoch 87/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1183 - acc: 0.9453     \n",
      "Epoch 88/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1162 - acc: 0.9460     \n",
      "Epoch 89/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1223 - acc: 0.9429     \n",
      "Epoch 90/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1192 - acc: 0.9449     \n",
      "Epoch 91/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1209 - acc: 0.9439     \n",
      "Epoch 92/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1179 - acc: 0.9458     \n",
      "Epoch 93/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1187 - acc: 0.9455     \n",
      "Epoch 94/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1172 - acc: 0.9458     \n",
      "Epoch 95/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1195 - acc: 0.9459     \n",
      "Epoch 96/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1188 - acc: 0.9452     \n",
      "Epoch 97/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1171 - acc: 0.9456     \n",
      "Epoch 98/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1187 - acc: 0.9455     \n",
      "Epoch 99/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1171 - acc: 0.9461     \n",
      "Epoch 100/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1180 - acc: 0.9466     \n",
      "Epoch 101/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1159 - acc: 0.9471     \n",
      "Epoch 102/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1162 - acc: 0.9467     \n",
      "Epoch 103/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1155 - acc: 0.9462     \n",
      "Epoch 104/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1141 - acc: 0.9475     \n",
      "Epoch 105/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1163 - acc: 0.9463     \n",
      "Epoch 106/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1138 - acc: 0.9476     \n",
      "Epoch 107/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1176 - acc: 0.9454     \n",
      "Epoch 108/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1165 - acc: 0.9462     \n",
      "Epoch 109/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1149 - acc: 0.9457     \n",
      "Epoch 110/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1158 - acc: 0.9466     \n",
      "Epoch 111/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1185 - acc: 0.9460     \n",
      "Epoch 112/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1139 - acc: 0.9475     \n",
      "Epoch 113/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1133 - acc: 0.9470     \n",
      "Epoch 114/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1172 - acc: 0.9465     \n",
      "Epoch 115/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1143 - acc: 0.9480     \n",
      "Epoch 116/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1159 - acc: 0.9462     \n",
      "Epoch 117/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1151 - acc: 0.9467     \n",
      "Epoch 118/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1135 - acc: 0.9481     \n",
      "Epoch 119/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1123 - acc: 0.9479     \n",
      "Epoch 120/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1157 - acc: 0.9473     \n",
      "Epoch 121/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1153 - acc: 0.9466     \n",
      "Epoch 122/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1152 - acc: 0.9465     \n",
      "Epoch 123/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1162 - acc: 0.9473     \n",
      "Epoch 124/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1134 - acc: 0.9475     \n",
      "Epoch 125/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1171 - acc: 0.9466     \n",
      "Epoch 126/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1135 - acc: 0.9484     \n",
      "Epoch 127/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1143 - acc: 0.9473     \n",
      "Epoch 128/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1132 - acc: 0.9478     \n",
      "Epoch 129/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1147 - acc: 0.9470     \n",
      "Epoch 130/500\n",
      "50176/50176 [==============================] - 1s - loss: 0.1145 - acc: 0.9473     \n",
      "Epoch 131/500\n",
      "47470/50176 [===========================>..] - ETA: 0s - loss: 0.1174 - acc: 0.9460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-47cbbbf830dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                             'strings, lists, numpy ndarrays, or TensorHandles.')\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           \u001b[0msubfeed_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m           if isinstance(subfeed_val,\n\u001b[1;32m   1080\u001b[0m                         int) and subfeed_dtype(subfeed_val) != subfeed_val:\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;34m\"\"\"The `DType` of elements in this tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bach.model.fit(X, Y, batch_size=101, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bach.model.save(\"models/saved_models/Bach/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
