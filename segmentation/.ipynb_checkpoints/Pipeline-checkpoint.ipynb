{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import copy\n",
    "import itertools\n",
    "import keras\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import scipy.misc\n",
    "import sklearn.feature_extraction\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import threading\n",
    "import gc\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy import ndimage\n",
    "from heapq import heappush, heappop\n",
    "from matplotlib import colors as mcolors\n",
    "from sys import stdout\n",
    "from __future__ import division\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_edges_3d(n_x, n_y, n_z=1):\n",
    "    \"\"\"Returns a list of edges for a 3D image.\n",
    "    Parameters\n",
    "    ===========\n",
    "    n_x: integer\n",
    "        The size of the grid in the x direction.\n",
    "    n_y: integer\n",
    "        The size of the grid in the y direction.\n",
    "    n_z: integer, optional\n",
    "        The size of the grid in the z direction, defaults to 1\n",
    "    \"\"\"\n",
    "    vertices = np.arange(n_x * n_y * n_z).reshape((n_x, n_y, n_z))\n",
    "    edges_deep = np.vstack((vertices[:, :, :-1].ravel(),\n",
    "                            vertices[:, :, 1:].ravel()))\n",
    "    edges_right = np.vstack((vertices[:, :-1].ravel(),\n",
    "                             vertices[:, 1:].ravel()))\n",
    "    edges_down = np.vstack((vertices[:-1].ravel(), vertices[1:].ravel()))\n",
    "    edges = np.hstack((edges_deep, edges_right, edges_down))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _compute_altitude_3d(edges, img):\n",
    "    n_x, n_y, n_z = img.shape\n",
    "    gradient = np.abs(img[edges[0] // (n_y * n_z),\n",
    "                          (edges[0] % (n_y * n_z)) // n_z,\n",
    "                          (edges[0] % (n_y * n_z)) % n_z] -\n",
    "                          img[edges[1] // (n_y * n_z),\n",
    "                          (edges[1] % (n_y * n_z)) // n_z,\n",
    "                          (edges[1] % (n_y * n_z)) % n_z])\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_graph(image):\n",
    "    \n",
    "    dtype=None\n",
    "    image = np.atleast_3d(image)\n",
    "    n_x, n_y, n_z = image.shape\n",
    "    edges = _make_edges_3d(n_x, n_y, n_z)\n",
    "    weights = _compute_altitude_3d(edges, image)\n",
    "    diag = image.ravel()\n",
    "    n_voxels = diag.size\n",
    "    diag_idx = np.arange(n_voxels)\n",
    "    i_idx = np.hstack((edges[0], edges[1]))\n",
    "    j_idx = np.hstack((edges[1], edges[0]))\n",
    "    matrix = sparse.coo_matrix((np.hstack((weights, weights, diag)),\n",
    "                              (np.hstack((i_idx, diag_idx)),\n",
    "                               np.hstack((j_idx, diag_idx)))),\n",
    "                              (n_voxels, n_voxels),\n",
    "                              dtype=dtype)\n",
    "    graph = nx.from_scipy_sparse_matrix(matrix)\n",
    "    graph.remove_edges_from(graph.selfloop_edges())\n",
    "    \n",
    "    mapping = map_node(image)\n",
    "    values = get_altitude_map(image)\n",
    "    \n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    nx.set_node_attributes(graph,'value',values=values)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_altitude_map(img):\n",
    "    values = dict()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            values[(row,col)] = img[row,col][0]\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_node(img):\n",
    "    \n",
    "    assert isinstance(img, np.ndarray), \"Not an image\"\n",
    "    \n",
    "    mapping = dict()\n",
    "    \n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            mapping[row * img.shape[1] + col] = ((row), (col))\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_positions(img):\n",
    "    positions = dict()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            positions[(row,col)] = (col,row)\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plant_seeds(graph, seeds):\n",
    "    \n",
    "    temp_graph = graph.copy()\n",
    "    \n",
    "    types_dict = dict()\n",
    "    assignment_dict = dict()\n",
    "    assignment_history = dict()\n",
    "\n",
    "    for x in temp_graph.nodes():\n",
    "        if x in seeds:\n",
    "            types_dict[x] = \"seed\"\n",
    "            assignment_dict[x] = x\n",
    "            assignment_history[x] = []\n",
    "        else:\n",
    "            types_dict[x] = \"node\"\n",
    "            assignment_dict[x] = 'none'\n",
    "            assignment_history[x] = []\n",
    "        \n",
    "            \n",
    "    nx.set_node_attributes(temp_graph, \"type\", types_dict)\n",
    "    nx.set_node_attributes(temp_graph, \"seed\", assignment_dict)\n",
    "    nx.set_node_attributes(temp_graph, \"path\", assignment_history)\n",
    "    \n",
    "    return temp_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_seeds(graph, n_seeds):\n",
    "    \n",
    "    seeds = []\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        seeds.append(random.choice(graph.nodes()))\n",
    "        \n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_graph_seed_assignments(graph):\n",
    "    assignments = dict()\n",
    "    for a, seed in enumerate(seeds):\n",
    "        nodes = list((n for n in graph if graph.node[n]['seed']==seeds[a]))\n",
    "        assignments.update(dict.fromkeys(nodes, a))\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spaced_colors(n):\n",
    "    max_value = 16581375 #255**3\n",
    "    interval = int(max_value / n)\n",
    "    colors = [hex(I)[2:].zfill(6) for I in range(0, max_value, interval)]\n",
    "    \n",
    "    return np.array([(int(i[:2], 16), int(i[2:4], 16), int(i[4:], 16)) for i in colors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projections(graph, seed, image):\n",
    "    '''This will output the relative labelings and save the RGB image to the relative labelings folder'''\n",
    "    \n",
    "    positions = get_image_positions(image)\n",
    "    assignments = get_graph_seed_assignments(graph)\n",
    "    \n",
    "    seeds = set(assignments.values())\n",
    "    n_seeds = len(seeds)\n",
    "    \n",
    "    seed_colors = get_spaced_colors(n_seeds)\n",
    "    \n",
    "    mask = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    \n",
    "    s = pd.Series(assignments)\n",
    "    s = s.values.reshape(image.shape)\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        a = s == x\n",
    "        if x == seed:\n",
    "            mask[a] = [0, 255, 0]\n",
    "        else:\n",
    "            mask[a] = [0, 0, 255]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prims_msf(G):\n",
    "    \n",
    "    MSF = nx.Graph()\n",
    "    nodes = G.nodes()\n",
    "    \n",
    "    s = filter(lambda (n, d): d['type'] == 'seed', G.nodes(data=True))\n",
    "    seeds = []\n",
    "    \n",
    "    edge_num = itertools.count(1)\n",
    "    num_edges = G.number_of_edges()\n",
    "    for x in s:\n",
    "        seeds.append(x[0])\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "\n",
    "    while nodes:\n",
    "        frontier = []\n",
    "        visited = []\n",
    "        for u in seeds:\n",
    "            nodes.remove(u)\n",
    "            visited.append(u)\n",
    "            \n",
    "            # Add seed to MSF\n",
    "            MSF.add_node(u, attr_dict=G.node[u])\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[u]['path'] = [u]\n",
    "            \n",
    "            # Push all edges\n",
    "            for u, v in G.edges(u):\n",
    "                \n",
    "                push(frontier, (G[u][v].get('weight', 1), u, v))\n",
    "        \n",
    "        \n",
    "\n",
    "        while frontier:\n",
    "            W, u, v = pop(frontier)   \n",
    "\n",
    "            if v in visited:\n",
    "                continue\n",
    "            \n",
    "            # Assign the node\n",
    "            G.node[v]['seed'] = G.node[u]['seed']\n",
    "            \n",
    "            # Add node and edge to MSF\n",
    "            MSF.add_node(v,attr_dict=G.node[v])\n",
    "            MSF.add_edge(u,v,attr_dict=G.edge[u][v])\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[v]['path'] = G.node[u]['path'] + [v]\n",
    "            \n",
    "            visited.append(v)\n",
    "            nodes.remove(v)\n",
    "            for v, w in G.edges(v):\n",
    "                if not w in visited:\n",
    "                    \n",
    "                    push(frontier, (G[v][w].get('weight', 1), v, w))\n",
    "    return MSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_of_view(master_image, center_pixel, crop_size):\n",
    "    \"\"\"Returns a crop of the master image centered on a specified pixel.\n",
    "    \n",
    "    Args:\n",
    "        master_image (numpy.ndarray): The master image to be cropped.\n",
    "        center_pixel (tuple): The pixel to be at the center of the crop.\n",
    "        window_size (tuple): The dimensions of the newly cropped image.\n",
    "        \n",
    "    Returns:\n",
    "        A cropped image of the master image with the specified pixel at the center.\n",
    "        \n",
    "    Examples:\n",
    "        fov = field_of_view(I, (0,0), (50,50))\"\"\"\n",
    "    \n",
    "    center = (center_pixel[0] + crop_size[0], center_pixel[1] + crop_size[1])\n",
    "\n",
    "    t_l = (center[0] - crop_size[0] // 2, center[1] - crop_size[1] // 2)\n",
    "    \n",
    "    return master_image[t_l[0]:t_l[0] + crop_size[0],t_l[1]:t_l[1] + crop_size[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assignment_mask(image, graph):\n",
    "    positions = get_image_positions(image)\n",
    "    assignments = get_graph_seed_assignments(graph)\n",
    "    \n",
    "    seeds = set(assignments.values())\n",
    "    n_seeds = len(seeds)\n",
    "    \n",
    "    seed_colors = get_spaced_colors(n_seeds)\n",
    "    \n",
    "    mask = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    \n",
    "    s = pd.Series(assignments)\n",
    "    s = s.values.reshape(image.shape)\n",
    "    \n",
    "    for x in range(n_seeds):\n",
    "        a = s == x\n",
    "        mask[a] = seed_colors[x]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_arc_topographical_distance(path, graph):\n",
    "    \"\"\"Returns the max-arc topographical distance of a path in a graph.\n",
    "    \n",
    "    Args:\n",
    "        path (list): A list of tuples defining the path traversed in graph.\n",
    "        graph (networkx.classes.graph.Graph): The graph containing the path.\n",
    "        \n",
    "    Returns:\n",
    "        float: the max-arc topographical distance of path.\"\"\"\n",
    "\n",
    "    \n",
    "    G = graph.subgraph(path)\n",
    "    \n",
    "    distance = -np.infty\n",
    "    \n",
    "    for x, y in G.edges_iter():\n",
    "        altitude = G.edge[x][y]['weight']\n",
    "        if altitude > distance:\n",
    "            distance = altitude\n",
    "            edge = (x, y)\n",
    "            \n",
    "    return distance, edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_boundary_probabilities(img):\n",
    "    \"\"\"Returns boundary probabilites for an image\"\"\"\n",
    "    \n",
    "    #Make a placeholder for boundary probabilities coming in next iteration of pipeline\n",
    "    return np.random.rand(img.shape[0],img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _AsList(x):\n",
    "    return x if isinstance(x, (list, tuple)) else [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_altitudes(edges):\n",
    "    \"\"\"\n",
    "    Calculates a batch of edges.\n",
    "    \n",
    "    Args:\n",
    "        edges: A `Dictionary` where the keys are the edges that need their altitudes calculated,\n",
    "        and the values are the images that will be used to calculate the edges.\n",
    "        \n",
    "    Returns:\n",
    "        Returns a copy of the dictionary where the original values of the dictionary are replaced\n",
    "        with the altitudes of the edges.    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.stack(edges.values())\n",
    "\n",
    "    with sess.as_default():\n",
    "        altitudes = sess.run(f_static, feed_dict={image_placeholder: x,\n",
    "                                                 keras.backend.learning_phase(): 0})\n",
    "        \n",
    "    for i, (u, v) in enumerate(edges):\n",
    "        altitude = altitudes[i][0]\n",
    "        edges[(u, v)] = altitude\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prims_on_demand(G, image_dict, seeds):\n",
    "    \"\"\"\n",
    "    Creates a minimum spanning forest from give graph.\n",
    "    \n",
    "    Args:\n",
    "        G (Graph): Graph to use for minimum spanning forest.\n",
    "        image_dict (Dictionary): The dictionary of nodes used to calculate an altitude.\n",
    "        \n",
    "    Returns:\n",
    "        MSF (Graph): Minimum spanning forest.\n",
    "    \"\"\"\n",
    "    \n",
    "    times = []\n",
    "    \n",
    "    nodes = G.nodes()\n",
    "        \n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    \n",
    "    while nodes:\n",
    "        frontier = []\n",
    "        visited = []\n",
    "        \n",
    "        for u in seeds:\n",
    "            nodes.remove(u)\n",
    "            visited.append(u)\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[u]['path'] = [u]\n",
    "            \n",
    "            uncalculated_edges = {}\n",
    "            \n",
    "            # Push all edges\n",
    "            for u, v in G.edges(u):\n",
    "                \n",
    "                # Fetch cropped image from dictionary and append it to the dictionary of edges to be\n",
    "                # calculated.\n",
    "                fov = image_dict[(v[0], v[1])]\n",
    "                uncalculated_edges[(u,v)] = fov\n",
    "                G.edge[u][v]['f_static_image'] = fov\n",
    "                G.edge[u][v]['f_dynamic_image'] = fov\n",
    "                \n",
    "            \n",
    "            uncalculated_edges = calculate_altitudes(uncalculated_edges)\n",
    "            \n",
    "            # Set the weight of the edges.\n",
    "            for i, (u, v) in enumerate(uncalculated_edges):\n",
    "                altitude = uncalculated_edges[(u, v)]\n",
    "                G.edge[u][v]['weight'] = altitude\n",
    "                push(frontier, (altitude, u, v))\n",
    "                \n",
    "        while frontier:\n",
    "            \n",
    "            cycletime_start = time.time()\n",
    "            \n",
    "            W, u, v = pop(frontier)\n",
    "            \n",
    "            if v in visited:\n",
    "                continue\n",
    "            \n",
    "            # Assign the node\n",
    "            G.node[v]['seed'] = G.node[u]['seed']\n",
    "            \n",
    "            # Store path.\n",
    "            G.node[v]['path'] = G.node[u]['path'] + [v]\n",
    "            \n",
    "            visited.append(v)\n",
    "            nodes.remove(v)\n",
    "            \n",
    "            uncalculated_edges = {}\n",
    "            \n",
    "            for v, w in G.edges(v):\n",
    "                if not w in visited:\n",
    "                    \n",
    "                    # Fetch cropped image from dictionary and append it to the dictionary of edges to be\n",
    "                    # calculated.\n",
    "                    fov = image_dict[(w[0], w[1])]\n",
    "                    uncalculated_edges[(v, w)] = fov\n",
    "                    G.edge[v][w]['f_static_image'] = fov\n",
    "                    G.edge[v][w]['f_dynamic_image'] = fov\n",
    "            \n",
    "            if len(uncalculated_edges) != 0:\n",
    "                \n",
    "                calculation_time_start = time.time()\n",
    "                \n",
    "                uncalculated_edges = calculate_altitudes(uncalculated_edges)\n",
    "                \n",
    "                calculation_time_end = time.time()\n",
    "                #print \"Calculation Time: {}\".format(calculation_time_end - calculation_time_start)\n",
    "                \n",
    "                for i, (v, w) in enumerate(uncalculated_edges):\n",
    "                    altitude = uncalculated_edges[(v,  w)]\n",
    "                    G.edge[v][w]['weight'] = altitude\n",
    "                    push(frontier, (altitude, v, w))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            cycletime_end = time.time()\n",
    "            times.append(cycletime_end - cycletime_start)\n",
    "    \n",
    "    print \"Average cycle time: {}\".format(np.mean(times))\n",
    "    print \"Number of cycles: {}\".format(len(times))\n",
    "    print \"Estimated time: {}\".format(len(times) * np.mean(times))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epoch_data(img_graph):\n",
    "    \"\"\"\n",
    "    Returns arrays containing edge calculation images and edge children count.\n",
    "    \n",
    "    Each edge weight corresponds to the same image used to calculate the edge.  For example,\n",
    "    if images[0] was used to compute edge ((0,0),(0,1)), then weights[0] would be the error\n",
    "    weight for that same edge.\n",
    "    \n",
    "    Args:\n",
    "        img_graph: (graph)\n",
    "    \n",
    "    Returns:\n",
    "        images (list): A list in which each element is the `ndarray` used to compute the\n",
    "        edge in the graph.\n",
    "        weights: (list): A list in which each element is the error weight for the edge.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    images = list()\n",
    "    weights = list()\n",
    "\n",
    "    for edge in img_graph.edges_iter():\n",
    "        try:\n",
    "            weights.append(img_graph.edge[edge[0]][edge[1]]['error_weight'])\n",
    "            images.append(img_graph.edge[edge[0]][edge[1]]['f_static_image'])\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    images = np.array(images)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    return images, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manually_check_loss(images, weights):\n",
    "    \"\"\"\n",
    "    Checks the loss of the given data.\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    with sess.as_default():\n",
    "        altitudes = sess.run(f_static, feed_dict={image_placeholder: images,\n",
    "                                                  keras.backend.learning_phase(): 0})\n",
    "        \n",
    "        loss = np.dot(weights, altitudes)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batches(x, y, max_batch_size=32):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        x: A numpy array of the input data\n",
    "        y: A numpy array of the output\n",
    "        max_batch_size: The maximum elements in each batch.\n",
    "\n",
    "    Returns: A list of batches.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    batches = math.ceil(x.shape[0] / max_batch_size)\n",
    "    x = np.array_split(x, batches)\n",
    "    y = np.array_split(y, batches)\n",
    "\n",
    "    return zip(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_deviation(ground_truth_path, shortest_path):\n",
    "    \"\"\"\n",
    "    Computes finds the edge where the ground truth path deviates from the shortest path.\n",
    "\n",
    "    Args:\n",
    "        ground_truth_path (list): The list of edges in the ground truth path.\n",
    "        shortest_path (list): The list of edges in the shortest path.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The first edge in which the two paths differ.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (ground_truth_node, shortest_path_node) in enumerate(zip(ground_truth_path, shortest_path)):\n",
    "        \n",
    "        if shortest_path_node != ground_truth_node:\n",
    "            return (ground_truth_path[i - 1], ground_truth_path[i])\n",
    "    else:\n",
    "        raise ValueError('No deviation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_false_cut(ground_truth_path, ground_truth_cuts, cut_edges):\n",
    "    \"\"\"\n",
    "    Finds the first false cut edge of a ground truth path.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        ground_truth_path (list): A list of nodes representing the path from the seed to the node.\n",
    "        ground_truth_cuts (list): A list of ground truth cut edges. \n",
    "        cut_edges (list): A list of cut edges from the minimum spanning forest.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The first edge in the ground truth path that is in the list of cut edges, but not in\n",
    "        in the list of ground truth edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, node in enumerate(ground_truth_path):\n",
    "        try:\n",
    "            edge = (ground_truth_path[i], ground_truth_path[i + 1])\n",
    "            if edge in cut_edges or tuple(reversed(edge)) in cut_edges:\n",
    "                if edge not in ground_truth_cuts or tuple(reversed(edge)) not in ground_truth_cuts:\n",
    "                    return edge\n",
    "\n",
    "        except IndexError:\n",
    "            print \"Something went wrong.\"\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_root_edge(shortest_path, ground_truth_path, cut_edges, ground_truth_cuts,\n",
    "                   edge_error_weights):\n",
    "    \"\"\"\n",
    "    Finds the root error edges for a node and inserts them into the dictionary.\n",
    "    \n",
    "    Args:\n",
    "        node (tuple): The node to find the root error edges for.\n",
    "        msf (Graph): The MSF used to find the shortest path.\n",
    "        constrained_msf (Graph): The constrained MSF used to find the ground truth path.\n",
    "        cut_edges (list): A list of tuples representing the cuts for the graph.\n",
    "        edge_error_weights (dictionary): The dictionary that holds all of the weights for \n",
    "        the root error edges.        \n",
    "    \"\"\"\n",
    "    \n",
    "    assigned_seed = shortest_path[0]\n",
    "    ground_truth_seed = ground_truth_path[0]\n",
    "\n",
    "    # Compute the root edge to increase (p(w)).\n",
    "    root_missing_cut_edge = find_missing_cut(shortest_path, ground_truth_cuts, \n",
    "                                             cut_edges)\n",
    "\n",
    "\n",
    "    # Increment the number of children for the root edge.\n",
    "    try:\n",
    "        edge_error_weights[root_missing_cut_edge]\n",
    "\n",
    "    except KeyError:\n",
    "\n",
    "        edge_error_weights[root_missing_cut_edge] = 0\n",
    "    finally:\n",
    "\n",
    "        edge_error_weights[root_missing_cut_edge] = \\\n",
    "        edge_error_weights[root_missing_cut_edge] - 1\n",
    "\n",
    "    # Compute the root edge to decrease.\n",
    "    if assigned_seed != ground_truth_seed:\n",
    "        root_false_cut_edge = find_first_false_cut(ground_truth_path,\n",
    "                                                   ground_truth_cuts,\n",
    "                                                   cut_edges)\n",
    "    else:\n",
    "        root_false_cut_edge = find_deviation(ground_truth_path, shortest_path)   \n",
    "\n",
    "    try:\n",
    "        edge_error_weights[root_false_cut_edge]\n",
    "    except KeyError:\n",
    "        edge_error_weights[root_false_cut_edge] = 0\n",
    "    finally:\n",
    "        edge_error_weights[root_false_cut_edge] = \\\n",
    "        edge_error_weights[root_false_cut_edge] + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_root_error_edge_children(shortest_paths, ground_truth_paths, cut_edges, ground_truth_cuts):\n",
    "    \"\"\"\n",
    "    Computes the root error edges used for a single training epoch of the system.\n",
    "\n",
    "    This function will prepare the weight function and the altitude prediction used for the loss.\n",
    "    The approach taken here is for every node in the graph, check if the node satisfies a failure \n",
    "    condition. If so, then add or subtract to the root error edge children.           \n",
    "\n",
    "    By construction of the MSF, the shortest path and the ground truth path are equal\n",
    "    for all nodes.  Conversely, they differ for incorrect nodes, causing the gound truth\n",
    "    path distance to exceed the shortest path distance.\n",
    "\n",
    "    TODO:\n",
    "        Write function to fetch root error false cuts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize edge error weights dictionary.\n",
    "    edge_error_weights = dict()\n",
    "\n",
    "    # Here multithreading is used to speed up root error edge computation.  Each thread \n",
    "    # computes the root error edges for a node.\n",
    "    threads = []\n",
    "    for node, shortest_path in shortest_paths.items():\n",
    "        if shortest_path != ground_truth_paths[node]:\n",
    "            thread = threading.Thread(target=find_root_edge, args=[shortest_path, ground_truth_paths[node],\n",
    "                                                                  cut_edges, ground_truth_cuts,\n",
    "                                                                  edge_error_weights])\n",
    "            threads.append(thread)\n",
    "            thread.start()            \n",
    "    \n",
    "    # Join threads\n",
    "    [thread.join() for thread in threads]\n",
    "\n",
    "    return edge_error_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_missing_cut(shortest_path, ground_truth_cuts, cut_edges):\n",
    "    \"\"\"\n",
    "    Computes the root error missing cut of a shortest path.\n",
    "\n",
    "    Every incorrect shortest path has at least one erroneous cut edge.  The first such\n",
    "    edge shall be called the path's root error edge p(w) and is always a missing cut.\n",
    "\n",
    "    Args:\n",
    "        shortest_path (list): The list of edges in the shortest path.\n",
    "        ground_truth_cuts (list): The list ground truth cuts for the ground truth segmentation.\n",
    "        cut_edges (list): The list of cut edges from the current segmentation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The first erroneous cut edge in the shortest path.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, node in enumerate(shortest_path):\n",
    "        try:\n",
    "            edge = (shortest_path[i], shortest_path[i + 1])\n",
    "            if edge in ground_truth_cuts or tuple(reversed(edge)) in ground_truth_cuts:\n",
    "                if edge not in cut_edges and tuple(reversed(edge)) not in cut_edges:\n",
    "                    return edge\n",
    "\n",
    "        except IndexError:\n",
    "            print \"Something went wrong.\"\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_paths(graph):\n",
    "    \"\"\"\n",
    "    This function will load all of the nodes paths in a graph into a dictionary for use.\n",
    "    \n",
    "    Args:\n",
    "        graph: The graph containing the paths to extract.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary where the keys are the nodes and the values are the paths from the \n",
    "        seed to the node.\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = {}\n",
    "    \n",
    "    for n, d in graph.nodes(data=True):\n",
    "        paths[n] = d['path']\n",
    "        \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Watershed:\n",
    "    \n",
    "    def __init__(self, window_size=(32,32)):\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def fit(self, images, ground_truth_images, epochs=16, batch_size=32, verbose=False):\n",
    "        \"\"\"\n",
    "        Fits the model given an image or set of images.\n",
    "        \n",
    "        Args:\n",
    "            images: A `numpy.ndarray` or list of arrays to be used to fit the model.\n",
    "            ground_truth_images: A `numpy.ndarray` or list of arrays to be used to fit the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.verbose=verbose\n",
    "        self.epochs = epochs\n",
    "        self.images = _AsList(images)\n",
    "        self.ground_truth_images = _AsList(ground_truth_images)\n",
    "        \n",
    "        for image, ground_truth_image in zip(self.images, self.ground_truth_images):\n",
    "            self.image = image\n",
    "            self.ground_truth_image = ground_truth_image\n",
    "            self._train_single()\n",
    "        \n",
    "    def _train_single(self):\n",
    "        \"\"\"\n",
    "        Trains the model on a single image. Training is composed of two steps. First the image is\n",
    "        segmented. Second, the model is updated. Before the model is trained, the ground truth\n",
    "        cut edges are calculated.\n",
    "        \"\"\"\n",
    "        \n",
    "        print \"Computing ground truth cuts.\"\n",
    "        \n",
    "        start = time.time()\n",
    "        self.ground_truth_cuts = self._compute_ground_truth_cuts(self.ground_truth_image,\n",
    "                                                                 self.seeds)\n",
    "        end = time.time()\n",
    "        \n",
    "        print (\"\\nTime: %f\" % (end - start))\n",
    "        \n",
    "        loss_timeline = list()\n",
    "        \n",
    "        for i in xrange(self.epochs):\n",
    "            self.current_epoch = i + 1\n",
    "            print \"\\n===========\"\n",
    "            print \"Epoch \", self.current_epoch\n",
    "            print \"===========\"\n",
    "            \n",
    "            print \"Computing the MSF\"\n",
    "            start = time.time()\n",
    "            segmentation = self.segment(self.image)\n",
    "            end = time.time()\n",
    "            print \"Done in {} seconds\".format(end - start)\n",
    "            \n",
    "            if self.verbose:\n",
    "                filename = \"training_images/epoch_{}.jpg\".format(self.current_epoch)\n",
    "                cv2.imwrite(filename, segmentation)\n",
    "            \n",
    "            loss_val = self._training_epoch()\n",
    "            loss_timeline.append(loss_val)\n",
    "            plt.plot(loss_timeline)\n",
    "            plt.savefig(\"training_images/Loss.jpg\")\n",
    "            \n",
    "            print \"Loss: \", loss_val\n",
    "        \n",
    "\n",
    "    def segment(self, image):\n",
    "        \"\"\"\n",
    "        Segments image.\n",
    "        \n",
    "        TODO:\n",
    "            Create and return segmented image.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._prepare_input_images()\n",
    "        \n",
    "        # Translate image to 4 connected grid graph.\n",
    "        self.image_graph = img_to_graph(image)\n",
    "            \n",
    "        # Plant seeds.\n",
    "        self.image_graph = plant_seeds(self.image_graph, self.seeds)\n",
    "        \n",
    "        # Compute image MSF.\n",
    "        self.image_graph =  prims_on_demand(self.image_graph, self.input_images, self.seeds)\n",
    "\n",
    "        # Compute cut edges\n",
    "        self.cut_edges = []\n",
    "        \n",
    "        [self.cut_edges.append(e) if self.image_graph.node[e[0]]['seed']\\\n",
    "        is not self.image_graph.node[e[1]]['seed'] else '' for e in\\\n",
    "        self.image_graph.edges_iter()]\n",
    "            \n",
    "        return assignment_mask(image, self.image_graph)\n",
    "        \n",
    "    def _training_epoch(self):\n",
    "        \"\"\"\n",
    "        This is the training epoch for each image.  The approach taken here is to first \n",
    "        create the constrained msf with the ground truth cut edges, then compute\n",
    "        the root error edges, afterwards compute and apply the updates for the model parameters.\n",
    "        \"\"\"\n",
    "        # Get the shortest paths from the image graph.\n",
    "        self.shortest_paths = get_paths(self.image_graph)\n",
    "        \n",
    "        # Compute the constrained MSF.\n",
    "        print \"Compute constrained MSF\"\n",
    "        start = time.time()\n",
    "        self.constrained_msf = self._compute_constrained_msf()\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        \n",
    "        # Get the ground truth paths from the constrained MSF\n",
    "        self.ground_truth_paths = get_paths(self.constrained_msf)\n",
    "        \n",
    "        print \"2. Identifying root edges and loss.\"\n",
    "        start = time.time()\n",
    "        edge_error_weights = compute_root_error_edge_children(self.shortest_paths, self.ground_truth_paths,\n",
    "                                                                 self.cut_edges, self.ground_truth_cuts)\n",
    "        \n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        \n",
    "        nx.set_edge_attributes(self.image_graph, 'error_weight', edge_error_weights)\n",
    "        \n",
    "        # Fetch the training data from the image graph.\n",
    "        images, weights = epoch_data(self.image_graph)\n",
    "        \n",
    "        # Split data into batches.\n",
    "        batches = create_batches(images, weights)\n",
    "        \n",
    "        # Compute loss.\n",
    "        print \"Computing Loss\"\n",
    "        start = time.time()\n",
    "        with sess.as_default():\n",
    "            loss_val = sess.run(loss, feed_dict={image_placeholder: images,\n",
    "                                                 gradient_weights: [weights],\n",
    "                                                 keras.backend.learning_phase(): 0})\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "        loss_val = loss_val[0][0]\n",
    "        #loss_val = 10\n",
    "            \n",
    "        # Update parameters\n",
    "        print \"Updating Parameters.\"\n",
    "        start = time.time()\n",
    "        with sess.as_default():\n",
    "            \n",
    "            # Zero out gradient accumulator.\n",
    "            sess.run(zero_ops)\n",
    "            \n",
    "            # Accumulate gradients.\n",
    "            for batch in batches:\n",
    "                sess.run(accum_ops, feed_dict={image_placeholder: batch[0],\n",
    "                                               gradient_weights: [batch[1]],\n",
    "                                               keras.backend.learning_phase(): 0})\n",
    "            \n",
    "            sess.run(train_step)\n",
    "        end = time.time()\n",
    "        print \"Done in {} seconds\".format(end - start)\n",
    "            \n",
    "        gc.collect()\n",
    "            \n",
    "        return loss_val\n",
    "    \n",
    "    \n",
    "    def _compute_ground_truth_cuts(self, ground_truth_image, seeds):\n",
    "        \"\"\"\n",
    "        Computes the ground truth cuts of the given image.\n",
    "        \n",
    "        Args:\n",
    "            ground_truth_image (ndarray): The image used to create the ground truth cuts.\n",
    "            seeds (list): A list of seeds to start watershed.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of ground truth cut edges.\n",
    "        \"\"\"\n",
    "        \n",
    "        ground_truth_graph = img_to_graph(ground_truth_image)\n",
    "        ground_truth_graph = plant_seeds(ground_truth_graph, self.seeds)\n",
    "        ground_truth_msf = prims_msf(ground_truth_graph)\n",
    "        \n",
    "        # Compute the ground truth cut edges\n",
    "        ground_truth_cuts = []\n",
    "        [ground_truth_cuts.append(e) if ground_truth_msf.node[e[0]]['seed']\\\n",
    "                 is not ground_truth_msf.node[e[1]]['seed'] else '' for e in\\\n",
    "                 ground_truth_graph.edges_iter()]\n",
    "        \n",
    "        ground_truth_segmentation = assignment_mask(self.image, ground_truth_graph)\n",
    "        filename = \"training_images/ground_truth_segmentation.jpg\"\n",
    "        cv2.imwrite(filename, ground_truth_segmentation)\n",
    "        \n",
    "        return ground_truth_cuts\n",
    "            \n",
    "\n",
    "    def _prepare_input_images(self):\n",
    "        \"\"\"\n",
    "        Preprocess images to be used in the prediction of the edges.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.padded_image = np.pad(self.image,(self.window_size [0],self.window_size [1]),'reflect')\n",
    "        \n",
    "        #boundary_probabilities = get_boundary_probabilities(self.padded_image)\n",
    "        boundary_probabilities = np.pad(self.ground_truth_image,(self.window_size [0],self.window_size [1]),'reflect')\n",
    "\n",
    "        #Augment the image with boundary probabilities\n",
    "        self.augmented_image = np.dstack((self.padded_image, boundary_probabilities))\n",
    "\n",
    "        # Get input images\n",
    "        self.input_images = dict()\n",
    "\n",
    "        for x in range(self.image.shape[0]):\n",
    "            for y in range(self.image.shape[1]):\n",
    "                node = (x, y)\n",
    "                self.input_images[node] = field_of_view(self.augmented_image, node, self.window_size)\n",
    "\n",
    "        \n",
    "    def _compute_constrained_msf(self):\n",
    "        \"\"\"\n",
    "        Returns the constained msf.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_cuts = self.image_graph.copy()\n",
    "        self.img_cuts.remove_edges_from(self.ground_truth_cuts)\n",
    "        return prims_msf(self.img_cuts)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def ground_truth_cuts(self):\n",
    "        return self.ground_truth_cuts\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def cut_edges(self):\n",
    "        return self.cut_edges\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def image_graph(self):\n",
    "        return self.image_graph\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def constrained_msf(self):\n",
    "        return self.constrained_msf\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def seeds(self):\n",
    "        return self.seeds\n",
    "    \n",
    "    \n",
    "    @seeds.setter\n",
    "    def seeds(self, seeds):\n",
    "        self.seeds = seeds\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def window_size(self):\n",
    "        return self.window_size\n",
    "    \n",
    "    @property\n",
    "    def image_dict(self):\n",
    "        return self.image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS THE START OF THE COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size\n",
    "image_tl = (0, 0)\n",
    "image_size = (100, 100)\n",
    "window_size = (15, 15)\n",
    "\n",
    "#import Images\n",
    "img = cv2.imread('data/slice_0/O', 0)\n",
    "gt = cv2.imread('data/slice_0/G', 0)\n",
    "\n",
    "#resize\n",
    "img = img[image_tl[0]:image_tl[0] + image_size[0],\n",
    "          image_tl[1]:image_tl[1] + image_size[1]]\n",
    "gt = gt[image_tl[0]:image_tl[0] + image_size[0],\n",
    "        image_tl[1]:image_tl[1] + image_size[1]]\n",
    "\n",
    "#set type\n",
    "img = img.astype(np.int16)\n",
    "gt = gt.astype(np.int16)\n",
    "\n",
    "# Import seeds\n",
    "seeds = []\n",
    "f = open(\"data/slice_0/seeds.txt\", 'r')\n",
    "for line in f:\n",
    "    y = int(float(re.split(' ', line)[0]))\n",
    "    x = int(float(re.split(' ', line)[1]))\n",
    "    seed = (x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "    if x >= image_tl[0] and x <= image_tl[0] + image_size[0]:\n",
    "        if y >= image_tl[1] and y <= image_tl[1] + image_size[1]:\n",
    "            x = x - image_tl[0]\n",
    "            y = y - image_tl[1]\n",
    "            seed = (x, y)\n",
    "            seeds.append(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This placeholder will contain the input images\n",
    "image_placeholder = tf.placeholder(tf.float32, shape=(None, window_size[0], window_size[0], 2))\n",
    "\n",
    "# Create model\n",
    "m = keras.layers.Conv2D(16, 5, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (image_placeholder)\n",
    "m = keras.layers.Conv2D(16, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(32, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=2) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(32, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=4) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(64, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=8) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(64, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=16) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Conv2D(128, 3, padding = 'same',\n",
    "                 activation='elu', dilation_rate=1) (m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Flatten()(m)\n",
    "m = keras.layers.Dense(8, activation='relu')(m)\n",
    "m = keras.layers.BatchNormalization() (m)\n",
    "m = keras.layers.Dense(1, activation='elu')(m)\n",
    "f_static = keras.layers.BatchNormalization() (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 2, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_2/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_3/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_4/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_3/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_3/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_5/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_4/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_4/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_4/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_4/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_6/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_5/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_5/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_5/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_5/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_7/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_6/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_6/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_6/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_6/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(28800, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_7/gamma:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_7/beta:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_7/moving_mean:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_7/moving_variance:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(8, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_8/gamma:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_8/beta:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_8/moving_mean:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_8/moving_variance:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_8/kernel:0' shape=(5, 5, 2, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_8/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_9/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_9/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_9/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_9/moving_mean:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_9/moving_variance:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_10/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_10/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_10/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_10/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_10/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_10/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_11/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_11/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_11/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_11/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_11/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_12/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_12/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_12/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_12/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_12/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_12/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_13/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_13/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_13/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_13/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_13/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_13/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_14/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_14/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_14/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_14/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_14/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_14/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(28800, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_15/gamma:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_15/beta:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_15/moving_mean:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_15/moving_variance:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_4/kernel:0' shape=(8, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_16/gamma:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_16/beta:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_16/moving_mean:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_16/moving_variance:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_6:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'value' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5ce7c26595b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0maccum_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccum_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Apply gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking)\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0maddition\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     return gen_state_ops.assign_add(\n\u001b[0;32m--> 239\u001b[0;31m         ref, value, use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m    240\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \"\"\"\n\u001b[1;32m     70\u001b[0m   result = _op_def_lib.apply_op(\"AssignAdd\", ref=ref, value=value,\n\u001b[0;32m---> 71\u001b[0;31m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    506\u001b[0m               raise ValueError(\n\u001b[1;32m    507\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    509\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    510\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'value' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "# This placeholder will hold the root error edge values.\n",
    "gradient_weights = tf.placeholder(tf.float32, shape=(1, None))\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.000001)\n",
    "\n",
    "tvs = None\n",
    "tvs = tf.trainable_variables()\n",
    "\n",
    "loss = tf.matmul(gradient_weights, f_static)\n",
    "\n",
    "# Accumulate gradients of predictions with respect to the parameters.\n",
    "accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]                                        \n",
    "zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "gvs = None\n",
    "gvs = opt.compute_gradients(loss, tvs)\n",
    "accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "\n",
    "# Apply gradients\n",
    "train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])\n",
    "\n",
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ground truth cuts.\n",
      "\n",
      "Time: 9.098259\n",
      "\n",
      "===========\n",
      "Epoch  1\n",
      "===========\n",
      "Computing the MSF\n",
      "Average cycle time: 0.00379955295949\n",
      "Number of cycles: 9988\n",
      "Estimated time: 37.9499349594\n",
      "Done in 41.3244018555 seconds\n",
      "Compute constrained MSF\n",
      "Done in 8.73009109497 seconds\n",
      "2. Identifying root edges and loss.\n",
      "Done in 15.6158750057 seconds\n",
      "Computing Loss\n",
      "Done in 0.514931201935 seconds\n",
      "Updating Parameters.\n",
      "Done in 0.817500829697 seconds\n",
      "Loss:  1033.41\n",
      "\n",
      "===========\n",
      "Epoch  2\n",
      "===========\n",
      "Computing the MSF\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-868e1e303314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-050aa3c0b83e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, images, ground_truth_images, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mground_truth_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-050aa3c0b83e>\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Computing the MSF\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msegmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Done in {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-050aa3c0b83e>\u001b[0m in \u001b[0;36msegment\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Compute image MSF.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_graph\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mprims_on_demand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Compute cut edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-872378d450a6>\u001b[0m in \u001b[0;36mprims_on_demand\u001b[0;34m(G, image_dict, seeds)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mcalculation_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0muncalculated_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_altitudes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muncalculated_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mcalculation_time_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-44490b70b5d8>\u001b[0m in \u001b[0;36mcalculate_altitudes\u001b[0;34m(edges)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         altitudes = sess.run(f_static, feed_dict={image_placeholder: x,\n\u001b[0;32m---> 18\u001b[0;31m                                                  keras.backend.learning_phase(): 0})\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w = Watershed(window_size=window_size)\n",
    "\n",
    "w.seeds = seeds\n",
    "\n",
    "w.fit(img, gt, epochs=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15, 15, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set image size\n",
    "image_tl = (0, 0)\n",
    "image_size = (15, 15)\n",
    "window_size = (15, 15)\n",
    "\n",
    "#import Images\n",
    "img = cv2.imread('1O.jpg', 0)\n",
    "\n",
    "#resize\n",
    "img = img[image_tl[0]:image_tl[0] + image_size[0],\n",
    "          image_tl[1]:image_tl[1] + image_size[1]]\n",
    "\n",
    "boundary_probabilities = np.random.randn(*img.shape)\n",
    "I_a = np.stack((img, boundary_probabilities), axis=2)\n",
    "I_a = np.expand_dims(I_a, 0)\n",
    "I_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction\n",
      "Prediction Done.  0.023135s\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    feed_dict = {image_placeholder: I_a,\n",
    "                 keras.backend.learning_phase(): 0}\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"Starting prediction\")\n",
    "    start = time.time()\n",
    "    p = sess.run(f_static, feed_dict=feed_dict)\n",
    "    end = time.time()\n",
    "    print(\"Prediction Done.  %fs\" %(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set image size\n",
    "image_tl = (300,300)\n",
    "\n",
    "#import Images\n",
    "img = cv2.imread('1O.jpg', 0)\n",
    "gt = cv2.imread('1G.jpg', 0)\n",
    "\n",
    "#resize\n",
    "img = img[image_tl[0]:image_tl[0] + image_size[0],\n",
    "          image_tl[1]:image_tl[1] + image_size[1]]\n",
    "gt = gt[image_tl[0]:image_tl[0] + image_size[0],\n",
    "        image_tl[1]:image_tl[1] + image_size[1]]\n",
    "\n",
    "#set type\n",
    "img = img.astype(np.int16)\n",
    "gt = gt.astype(np.int16)\n",
    "\n",
    "# Save image\n",
    "plt.imsave(\"image\", cv2.resize(img, (1000,1000)), cmap='gray')\n",
    "plt.clf()\n",
    "\n",
    "# Import seeds\n",
    "seeds = []\n",
    "f = open(\"seeds1G.txt\", 'r')\n",
    "for line in f:\n",
    "    y = int(float(re.split(' ', line)[0]))\n",
    "    x = int(float(re.split(' ', line)[1]))\n",
    "    seed = (x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "    if x >= image_tl[0] and x <= image_tl[0] + image_size[0]:\n",
    "        if y >= image_tl[1] and y <= image_tl[1] + image_size[1]:\n",
    "            x = x - image_tl[0]\n",
    "            y = y - image_tl[1]\n",
    "            seed = (x, y)\n",
    "            seeds.append(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.seeds = seeds\n",
    "\n",
    "segmentation = w.segment(img)\n",
    "\n",
    "\n",
    "filename = \"test.jpg\"\n",
    "cv2.imwrite(filename, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import heapq\n",
    "import random\n",
    "\n",
    "push = heapq.heappush\n",
    "pop = heapq.heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier = []\n",
    "he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71401309967\n",
      "1.7565369606\n"
     ]
    }
   ],
   "source": [
    "frontier = []\n",
    "for x in range(319200):\n",
    "    frontier.append(random.randint(-1, 1000))\n",
    "\n",
    "start = time.time()\n",
    "for x in range(400*400):\n",
    "    pop(frontier)\n",
    "    for y in range(4):\n",
    "        push(frontier, random.randint(-1, 1000))\n",
    "print time.time() - start\n",
    "\n",
    "frontier = []\n",
    "for x in range(319200):\n",
    "    frontier.append(random.randint(-1, 1000))\n",
    "\n",
    "start = time.time()\n",
    "for x in range(400*400):\n",
    "    pop(frontier)\n",
    "    for y in range(4):\n",
    "        push(frontier, random.randint(-1, 1000))\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frontier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.98430633545e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "assignments[1] = assignments[2]\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.48362731934e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "push(frontier, (1))\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000303030014038\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pop(frontier)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.239776611328"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.19888305664e-05 * 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
