{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import time\n",
    "from heapq import heappop as pop\n",
    "from heapq import heappush as push\n",
    "\n",
    "import keras\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from utils import display_utils\n",
    "from utils import graph_utils\n",
    "from utils import preprocessing_utils\n",
    "from utils import relative_assignments\n",
    "\n",
    "\n",
    "class Chopin:\n",
    "    def __init__(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def build(self, receptive_field_shape, learning_rate=0.001):\n",
    "\n",
    "        self.receptive_field_shape = receptive_field_shape\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        self.static_input = tf.placeholder(tf.float32,\n",
    "                                           shape=(None, self.receptive_field_shape[0],\n",
    "                                                  self.receptive_field_shape[1],\n",
    "                                                  2))\n",
    "\n",
    "        self.dynamic_input = tf.placeholder(tf.float32,\n",
    "                                            shape=(None, self.receptive_field_shape[0],\n",
    "                                                   self.receptive_field_shape[1], 3))\n",
    "        label_input = tf.placeholder(tf.float32,\n",
    "                                   shape=(None, 64))\n",
    "\n",
    "        # Static Body.\n",
    "        static = keras.layers.Conv2D(16, 5, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(self.static_input)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(16, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=2)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=4)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=8)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=16)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(128, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Flatten()(static)\n",
    "\n",
    "        # Dynamic body.\n",
    "        dynamic = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=4)(self.dynamic_input)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=8)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=16)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=1)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Flatten()(dynamic)\n",
    "\n",
    "        merge = keras.layers.concatenate([static, dynamic], 1)\n",
    "\n",
    "        self.altitude = keras.layers.Dense(1024, activation='relu')(merge)\n",
    "        embedding1 = keras.layers.Embedding(1024, 64)(label_input)\n",
    "        altitude, state = keras.layers.GRU(64, return_state=True)(embedding1)\n",
    "        self.altitude = keras.layers.BatchNormalization()(self.altitude)\n",
    "        self.altitude = keras.layers.Dense(1, activation='elu')(self.altitude)\n",
    "\n",
    "        # This placeholder will hold the root error edge values.\n",
    "        self.gradient_weights = tf.placeholder(tf.float32, shape=(1, None))\n",
    "\n",
    "        # Define optimizer\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        tvs = tf.trainable_variables()\n",
    "\n",
    "        self.loss = tf.matmul(self.gradient_weights, self.altitude)\n",
    "\n",
    "        # Accumulate gradients of predictions with respect to the parameters.\n",
    "        accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
    "        self.zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "        gvs = opt.compute_gradients(self.loss, tvs)\n",
    "#         print(gvs)\n",
    "#         self.accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "        \n",
    "        self.accum_ops = []\n",
    "        \n",
    "        for i, gv in enumerate(gvs):\n",
    "            print(gv)\n",
    "            self.accum_ops.append(accum_vars[i].assign_add(gv[0]))\n",
    "\n",
    "        # Apply gradients\n",
    "        self.train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])\n",
    "\n",
    "    def predict_altitudes(self, static_images, dynamic_images):\n",
    "        \"\"\"\n",
    "        Predicts the altitude of one or more edges given the static image and the dynamic image.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            static_images: a numpy.ndarray of shape [None, receptive_field_shape[0],\n",
    "            receptive_field_shape[1], 2] images from the original image that are\n",
    "            augmented with boundary probabilities and are cropped to the same size\n",
    "            of the receptive field.\n",
    "\n",
    "            dynamic_images: a numpy.ndarray of rgb images of shape [None, receptive_field_shape[0],\n",
    "            receptive_field_shape[1], 3] that represent the relative assignments.\n",
    "\n",
    "        Returns:\n",
    "            The altitudes of the edges.\n",
    "        \"\"\"\n",
    "\n",
    "        with self.sess.as_default():\n",
    "            feed_dict = {self.static_input: static_images,\n",
    "                         self.dynamic_input: dynamic_images,\n",
    "                         keras.backend.learning_phase(): 0}\n",
    "\n",
    "            altitudes = self.sess.run(self.altitude, feed_dict)\n",
    "\n",
    "        return altitudes\n",
    "\n",
    "    def initialize_session(self):\n",
    "        \"\"\"\n",
    "        Initializes a session in TensorFlow.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.sess._closed:\n",
    "            self.sess.close()\n",
    "\n",
    "        self.sess = tf.InteractiveSession()\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with self.sess.as_default():\n",
    "            try:\n",
    "                # Restore variables from disk.\n",
    "                saver.restore(self.sess, filepath)\n",
    "                # print(\"Model restored.\")\n",
    "            except:\n",
    "                self.sess.run(tf.global_variables_initializer())\n",
    "                save_path = saver.save(self.sess, filepath)\n",
    "\n",
    "    def save_model(self, filepath, global_step):\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with self.sess.as_default():\n",
    "            save_path = saver.save(self.sess, filepath, global_step)\n",
    "\n",
    "    def predicted_msf(self, I_a, graph, seeds):\n",
    "        n_visited = 0\n",
    "        msf = nx.Graph()\n",
    "        visited = np.zeros(I_a.shape[:-1])\n",
    "        frontier = []\n",
    "\n",
    "        ra = relative_assignments.RelativeAssignments(seeds,\n",
    "                                                      (I_a.shape[0],\n",
    "                                                       I_a.shape[1]),\n",
    "                                                      self.receptive_field_shape)\n",
    "        static_input_images = preprocessing_utils.prepare_input_images(I_a, height=self.receptive_field_shape[0],\n",
    "                                                                       width=self.receptive_field_shape[1])\n",
    "        print(\"Starting gradient segmentation...\")\n",
    "        start = time.time()\n",
    "\n",
    "        for s in seeds:\n",
    "\n",
    "            # Add node to MSF.\n",
    "            msf.add_node(s)\n",
    "\n",
    "            # Assign seed to itself.\n",
    "            msf.node[s]['seed'] = s\n",
    "            ra.assign_node(s, seeds.index(s))\n",
    "            n_visited += 1\n",
    "            print(n_visited / visited.size)\n",
    "\n",
    "            visited[s[0], s[1]] = 1\n",
    "\n",
    "            # Push all edges\n",
    "            for u, v in graph.edges(s):\n",
    "                seed_index = seeds.index(msf.node[u]['seed'])\n",
    "                static_image = static_input_images[v[0] * I_a.shape[1] + v[1]]\n",
    "                dynamic_image = ra.prepare_images([(v, seed_index)])[0]\n",
    "                static_image = np.expand_dims(static_image, 0)\n",
    "                dynamic_image = np.expand_dims(dynamic_image, 0)\n",
    "                altitude_value = self.predict_altitudes(static_image,\n",
    "                                                          dynamic_image)\n",
    "                graph.edge[u][v]['static_image'] = static_image\n",
    "                graph.edge[u][v]['dynamic_image'] = dynamic_image\n",
    "                graph.edge[u][v]['weight'] = altitude_value\n",
    "\n",
    "                push(frontier, (graph.edge[u][v]['weight'], u, v))\n",
    "\n",
    "        while frontier:\n",
    "            W, u, v = pop(frontier)\n",
    "\n",
    "            # If the node is already visited, then skip assigning it.\n",
    "            if visited[v[0], v[1]] == 1:\n",
    "                continue\n",
    "\n",
    "            msf.add_node(v)\n",
    "\n",
    "            # Add edge to MSF.\n",
    "            msf.add_edge(u, v, graph.get_edge_data(u, v))\n",
    "\n",
    "            # Assign the node\n",
    "            msf.node[v]['seed'] = msf.node[u]['seed']\n",
    "            ra.assign_node(v, seeds.index(msf.node[u]['seed']))\n",
    "\n",
    "            # Mark as visited\n",
    "            visited[v[0], v[1]] = 1\n",
    "\n",
    "            # Increment the number of visited nodes\n",
    "            if n_visited % 100 == 0:\n",
    "                n_visited += 1\n",
    "                print(n_visited, visited.size, n_visited / visited.size)\n",
    "\n",
    "            for v, w in graph.edges(v):\n",
    "                if visited[w[0], w[1]] == 0:\n",
    "                    # Calculate the altitude of the edge.\n",
    "                    seed_index = seeds.index(msf.node[v]['seed'])\n",
    "                    static_image = static_input_images[w[0] * I_a.shape[1] + w[1]]\n",
    "                    dynamic_image = ra.prepare_images([(w, seed_index)])[0]\n",
    "                    static_image = np.expand_dims(static_image, 0)\n",
    "                    dynamic_image = np.expand_dims(dynamic_image, 0)\n",
    "                    altitude_value = self.predict_altitudes(static_image,\n",
    "                                                              dynamic_image)\n",
    "                    graph.edge[v][w]['static_image'] = static_image\n",
    "                    graph.edge[v][w]['dynamic_image'] = dynamic_image\n",
    "                    graph.edge[v][w]['weight'] = altitude_value\n",
    "                    push(frontier, (altitude_value, v, w))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Segmentation done: %fs\" % (end - start))\n",
    "\n",
    "        return msf\n",
    "\n",
    "    def constrained_msf(self, I_a, graph, msf, seeds, gt_cuts):\n",
    "\n",
    "        constrained_msf = nx.Graph()\n",
    "\n",
    "        visited = np.zeros(I_a.shape[:-1])\n",
    "        frontier = []\n",
    "\n",
    "        print(\"Starting gradient segmentation...\")\n",
    "        start = time.time()\n",
    "\n",
    "        for s in seeds:\n",
    "\n",
    "            # Add node to MSF.\n",
    "            constrained_msf.add_node(s)\n",
    "\n",
    "            # Assign seed to itself.\n",
    "            constrained_msf.node[s]['seed'] = s\n",
    "\n",
    "            visited[s[0], s[1]] = 1\n",
    "\n",
    "            # Push all edges\n",
    "            for u, v in graph.edges(s):\n",
    "                if (u, v) not in gt_cuts:\n",
    "                    push(frontier, (graph.edge[u][v]['weight'], u, v))\n",
    "\n",
    "        while frontier:\n",
    "            W, u, v = pop(frontier)\n",
    "\n",
    "            # If the node is already visited, then skip assigning it.\n",
    "            if visited[v[0], v[1]] == 1:\n",
    "                continue\n",
    "\n",
    "            constrained_msf.add_node(v)\n",
    "\n",
    "            # Add edge to MSF.msf\n",
    "            constrained_msf.add_edge(u, v, graph.get_edge_data(u, v))\n",
    "\n",
    "            # Assign the node\n",
    "            constrained_msf.node[v]['seed'] = constrained_msf.node[u]['seed']\n",
    "\n",
    "            visited[v[0], v[1]] = 1\n",
    "\n",
    "            for v, w in graph.edges(v):\n",
    "                if visited[w[0], w[1]] == 0:\n",
    "                    if (v, w) not in gt_cuts and (w, v) not in gt_cuts:\n",
    "                        push(frontier, (graph.edge[v][w]['weight'], v, w))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Segmentation done: %fs\" % (end - start))\n",
    "\n",
    "        return constrained_msf\n",
    "    \n",
    "    def train_on_image(self, img, I_a, gt_cuts, seeds, graph):\n",
    "        msf = self.predicted_msf(I_a, graph, seeds)\n",
    "        cuts = graph_utils.get_cut_edges(graph, msf)\n",
    "        constrained_msf = self.constrained_msf(I_a, graph, msf, seeds, gt_cuts)\n",
    "        shortest_paths, ground_truth_paths = graph_utils.get_paths(graph, msf, constrained_msf)\n",
    "\n",
    "        children = graph_utils.compute_root_error_edge_children(shortest_paths,\n",
    "                                                                ground_truth_paths, cuts,\n",
    "                                                                gt_cuts)\n",
    "\n",
    "        segmentations = display_utils.assignments(np.zeros_like(img), msf, seeds)\n",
    "\n",
    "        weights = []\n",
    "        static_images = []\n",
    "        dynamic_images = []\n",
    "\n",
    "        for (u, v), weight in children.iteritems():\n",
    "            static_images.append(graph.get_edge_data(u, v)['static_image'])\n",
    "            dynamic_images.append(graph.get_edge_data(u, v)['dynamic_image'])\n",
    "            weights.append(weight)\n",
    "            altitude_val = graph.get_edge_data(u, v)['weight']\n",
    "\n",
    "        batches = zip(preprocessing_utils.create_batches(np.expand_dims(np.stack(weights), 1)),\n",
    "                      preprocessing_utils.create_batches(np.concatenate(static_images)),\n",
    "                      preprocessing_utils.create_batches(np.concatenate(dynamic_images)))\n",
    "\n",
    "        loss = 0\n",
    "        with self.sess.as_default():\n",
    "            self.sess.run(self.zero_ops)\n",
    "\n",
    "            for w, s, d in batches:\n",
    "                feed_dict = {self.gradient_weights: w.transpose(),\n",
    "                             self.static_input: s,\n",
    "                             self.dynamic_input: d,\n",
    "                             keras.backend.learning_phase(): 0}\n",
    "\n",
    "                self.sess.run(\n",
    "                    self.accum_ops, feed_dict)\n",
    "                loss += self.sess.run(self.loss, feed_dict)[0][0]\n",
    "\n",
    "            self.sess.run(self.train_step)\n",
    "\n",
    "        return loss, segmentations, cuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "receptive_field_shape = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'gradients/conv2d_1/convolution_grad/tuple/control_dependency_1:0' shape=(5, 5, 2, 16) dtype=float32>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 2, 16) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_1/bias:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_48:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_46:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_1/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_1/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_2/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 16, 16) dtype=float32>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_2/bias:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_44:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_42:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_2/beta:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_2/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_2/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(16,) dtype=float32>, <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(16,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_3/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_3/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_3/bias:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_40:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_38:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_3/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/moving_mean:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_3/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_3/moving_variance:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_4/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 32, 32) dtype=float32>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_4/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_4/bias:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_35:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_30:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_4/beta:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_4/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_4/moving_mean:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_4/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_4/moving_variance:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_5/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_5/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_5/bias:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_27:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_5/gamma:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_22:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_5/beta:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_5/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_5/moving_mean:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_5/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_5/moving_variance:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_6/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_6/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_6/bias:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_19:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_6/gamma:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_14:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_6/beta:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_6/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_6/moving_mean:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_6/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_6/moving_variance:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_7/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 64, 128) dtype=float32>, <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_7/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>, <tf.Variable 'conv2d_7/bias:0' shape=(128,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_11:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(128,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_6:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_7/beta:0' shape=(128,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_7/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_7/moving_mean:0' shape=(128,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_7/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(128,) dtype=float32>, <tf.Variable 'batch_normalization_7/moving_variance:0' shape=(128,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_8/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 32) dtype=float32>, <tf.Variable 'conv2d_8/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_8/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_8/bias:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_36:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_8/gamma:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_33:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_8/beta:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_8/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_8/moving_mean:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_8/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_8/moving_variance:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_9/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 32, 32) dtype=float32>, <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_9/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_9/bias:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_28:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_9/gamma:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_25:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_9/beta:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_9/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_9/moving_mean:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_9/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(32,) dtype=float32>, <tf.Variable 'batch_normalization_9/moving_variance:0' shape=(32,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_10/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_10/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_10/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_10/bias:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_20:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_10/gamma:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_17:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_10/beta:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_10/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_10/moving_mean:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_10/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_10/moving_variance:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_11/convolution_grad/tuple/control_dependency_1:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/conv2d_11/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_11/bias:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_12:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_11/gamma:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/AddN_9:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_11/beta:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_11/cond/batchnorm/mul_2/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_11/moving_mean:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/batch_normalization_11/cond/batchnorm/add/Switch_grad/cond_grad:0' shape=(64,) dtype=float32>, <tf.Variable 'batch_normalization_11/moving_variance:0' shape=(64,) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/dense_1/MatMul_grad/tuple/control_dependency_1:0' shape=(27648, 1024) dtype=float32>, <tf.Variable 'dense_1/kernel:0' shape=(27648, 1024) dtype=float32_ref>)\n",
      "(<tf.Tensor 'gradients/dense_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>, <tf.Variable 'dense_1/bias:0' shape=(1024,) dtype=float32_ref>)\n",
      "(None, <tf.Variable 'embedding_1/embeddings:0' shape=(1024, 64) dtype=float32_ref>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'value' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-26b176587eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mchopin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChopin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchopin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreceptive_field_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-431752b8266f>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, receptive_field_shape, learning_rate)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccum_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Apply gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking)\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0maddition\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \"\"\"\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     return gen_state_ops.assign_add(\n\u001b[0;32m--> 242\u001b[0;31m         ref, value, use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m    243\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.pyc\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m   result = _op_def_lib.apply_op(\"AssignAdd\", ref=ref, value=value,\n\u001b[0;32m---> 69\u001b[0;31m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/collin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    506\u001b[0m               raise ValueError(\n\u001b[1;32m    507\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    509\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    510\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'value' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "chopin = Chopin()\n",
    "chopin.build(receptive_field_shape, learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
