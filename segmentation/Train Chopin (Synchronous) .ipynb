{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import keras\n",
    "\n",
    "from models import BachNet\n",
    "from models import ChopinNet\n",
    "\n",
    "import networkx as nx\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "from heapq import heappop as pop\n",
    "from heapq import heappush as push\n",
    "from utils import graph_utils\n",
    "from utils import display_utils\n",
    "from utils import prediction_utils\n",
    "from utils import preprocessing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "test_path = \"data/test\"\n",
    "\n",
    "input_path = \"input\"\n",
    "output_path = \"output\"\n",
    "\n",
    "gt_tag = \"gt\"\n",
    "\n",
    "receptive_field_shape = (12, 12)\n",
    "n_epochs = 32\n",
    "save_rate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image:  740_1450_gt\n",
      "Loading image:  740_1460\n",
      "Loading image:  740_1460\n",
      "Loading image:  740_1450\n",
      "Loading image:  740_1450\n",
      "Loading image:  740_1460_gt\n"
     ]
    }
   ],
   "source": [
    "bach = BachNet.BachNet()\n",
    "bach.build(receptive_field_shape, 1)\n",
    "bach.load_model('models/saved_models/Bach/model.h5')\n",
    "\n",
    "batch = dict()\n",
    "input_gen = prediction_utils.input_generator(bach, train_path, input_path, gt_tag)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        f_name, img, bps, I_a, gt, gt_cuts, seeds = next(input_gen)\n",
    "        graph = graph_utils.prims_initialize(img)\n",
    "        batch[f_name] = img, bps, I_a, gt, gt_cuts, seeds, graph\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopin = ChopinNet.Chopin()\n",
    "chopin.build(receptive_field_shape, learning_rate=1e-5)\n",
    "#chopin.load_model(\"models/saved_model/Chopin/checkpoint\")\n",
    "chopin.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 740_1460\n",
      "Epoch: 0\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.659226s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033889s\n",
      "Epoch: 1\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.643182s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034713s\n",
      "Saving Model\n",
      "Epoch: 2\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.653809s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036342s\n",
      "Epoch: 3\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.771202s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036137s\n",
      "Saving Model\n",
      "Epoch: 4\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.716843s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.032923s\n",
      "Epoch: 5\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.792004s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035314s\n",
      "Saving Model\n",
      "Epoch: 6\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 6.396902s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033961s\n",
      "Epoch: 7\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.759385s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.039664s\n",
      "Saving Model\n",
      "Epoch: 8\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.804456s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035944s\n",
      "Epoch: 9\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.835094s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.037131s\n",
      "Saving Model\n",
      "Epoch: 10\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.722036s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.033084s\n",
      "Epoch: 11\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.975919s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034443s\n",
      "Saving Model\n",
      "Epoch: 12\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.659364s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035178s\n",
      "Epoch: 13\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.663060s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.040525s\n",
      "Saving Model\n",
      "Epoch: 14\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.780574s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036295s\n",
      "Epoch: 15\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.732369s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.034493s\n",
      "Saving Model\n",
      "Epoch: 16\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.742772s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.035001s\n",
      "Epoch: 17\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.703703s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036424s\n",
      "Saving Model\n",
      "Epoch: 18\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.811634s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.036418s\n",
      "Epoch: 19\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 5.807911s\n",
      "Starting gradient segmentation...\n",
      "Segmentation done: 0.032321s\n",
      "Saving Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7e985dd97e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mchopin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saved_models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch_{}_bw.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/PycharmProjects/Learned-Watershed-Segmentation/segmentation/models/ChopinNet.pyc\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, filepath, global_step)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredicted_msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1494\u001b[0m           checkpoint_file, meta_graph_suffix=meta_graph_suffix)\n\u001b[1;32m   1495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m         clear_extraneous_savers=clear_extraneous_savers)\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, **kwargs)\u001b[0m\n\u001b[1;32m   1765\u001b[0m       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1768\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[0;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0msaver_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc\u001b[0m in \u001b[0;36mcreate_meta_graph_def\u001b[0;34m(meta_info_def, graph_def, saver_def, collection_list, graph, export_scope, exclude_nodes, clear_extraneous_savers)\u001b[0m\n\u001b[1;32m    534\u001b[0m                          \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                          \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                          exclude_nodes=exclude_nodes)\n\u001b[0m\u001b[1;32m    537\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc\u001b[0m in \u001b[0;36madd_collection_def\u001b[0;34m(meta_graph_def, key, graph, export_scope, exclude_nodes, override_contents)\u001b[0m\n\u001b[1;32m    402\u001b[0m   \u001b[0;31m# Remove nodes that should not be exported from the collection list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   collection_list = [x for x in collection_list if\n\u001b[0;32m--> 404\u001b[0;31m                      _should_include_node(x, export_scope, exclude_nodes)]\n\u001b[0m\u001b[1;32m    405\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcollection_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc\u001b[0m in \u001b[0;36m_should_include_node\u001b[0;34m(node_or_node_name, export_scope, exclude_nodes)\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_node_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mnode_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_or_node_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;31m# Keep the object that we don't know how to process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/serl/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4579dfb250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_loss_timeline = []\n",
    "loss_timelines = dict()\n",
    "loss_file = open(\"data/train/chopin/global_loss.txt\", 'w')\n",
    "loss_file.write(\"f_name\\tepoch\\tloss\\n\")\n",
    "\n",
    "for f_name, (img, bps, I_a, gt, gt_cuts, seeds, graph) in batch.iteritems():\n",
    "    print(\"Training on\", f_name)\n",
    "    foldername = os.path.join(train_path, \"chopin\", f_name)\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        loss, segmentations, cuts = chopin.train_on_image(img, I_a, gt_cuts, seeds, graph)\n",
    "        \n",
    "        if epoch % save_rate:\n",
    "            print(\"Saving Model\")\n",
    "            chopin.save_model(os.path.join(foldername, \"saved_models\", \"model\"), epoch)\n",
    "            chopin.save_model(\"models/saved_models/Chopin/chopin\", epoch)\n",
    "        \n",
    "        plt.imsave(os.path.join(foldername, \"epoch_{}_bw.png\".format(epoch)), display_utils.view_boundaries(np.zeros_like(img), cuts))\n",
    "\n",
    "        mask = display_utils.transparent_mask(display_utils.view_boundaries(img, gt_cuts), segmentations, alpha=0.75)\n",
    "        plt.imsave(os.path.join(foldername, \"epoch_{}_overlay.png\".format(epoch)), mask)\n",
    "        \n",
    "        loss_file.write(f_name + \"\\t\" + str(epoch) + \"\\t\" + str(loss) + \"\\n\")\n",
    "        loss_file.flush()\n",
    "        \n",
    "        global_loss_timeline.append(loss)\n",
    "        \n",
    "        try:\n",
    "            loss_timelines[f_name].append(loss)\n",
    "        except KeyError:\n",
    "            loss_timelines[f_name] = [loss]\n",
    "            \n",
    "        plt.plot(loss_timelines[f_name])\n",
    "        plt.savefig(os.path.join(foldername, \"local_loss\"))\n",
    "        \n",
    "        plt.gcf().clear()\n",
    "            \n",
    "        plt.plot(global_loss_timeline)\n",
    "        plt.savefig(\"data/train/chopin/global_loss\")\n",
    "        \n",
    "        plt.gcf().clear()\n",
    "            \n",
    "loss_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/chopin/740_1460'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopin.save_model(foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(foldername, \"saved_models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.join(foldername, \"saved_models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/chopin/740_1460/saved_models/1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(foldername, \"saved_models\", str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
