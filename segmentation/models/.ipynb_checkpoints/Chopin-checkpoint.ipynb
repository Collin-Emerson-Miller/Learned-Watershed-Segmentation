{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2fa60b44b16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named utils"
     ]
    }
   ],
   "source": [
    "from utils import graph_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "receptive_field_shape = (23, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Chopin:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def build(self, receptive_field_shape):\n",
    "\n",
    "        self.receptive_field_shape = receptive_field_shape\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        self.static_input = tf.placeholder(tf.float32,\n",
    "                                           shape=(None, self.receptive_field_shape[0],\n",
    "                                                  self.receptive_field_shape[1],\n",
    "                                                  2))\n",
    "\n",
    "        self.dynamic_input = tf.placeholder(tf.float32,\n",
    "                                            shape=(None, self.receptive_field_shape[0],\n",
    "                                                   self.receptive_field_shape[1], 3))\n",
    "\n",
    "        # Static Body.\n",
    "        static = keras.layers.Conv2D(16, 5, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(self.static_input)\n",
    "        static = keras.layers.Conv2D(16, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=2)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=4)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=8)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=16)(static)\n",
    "        static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Conv2D(128, 3, padding='same',\n",
    "                                     activation='elu', dilation_rate=1)(static)\n",
    "        # static = keras.layers.BatchNormalization()(static)\n",
    "        static = keras.layers.Flatten()(static)\n",
    "\n",
    "        # Dynamic body.\n",
    "        dynamic = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=4)(self.dynamic_input)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(32, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=8)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=16)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Conv2D(64, 3, padding='same',\n",
    "                                      activation='elu', dilation_rate=1)(dynamic)\n",
    "        dynamic = keras.layers.BatchNormalization()(dynamic)\n",
    "        dynamic = keras.layers.Flatten()(dynamic)\n",
    "\n",
    "        merge = keras.layers.concatenate([static, dynamic], 1)\n",
    "\n",
    "        self.altitude = keras.layers.Dense(16, activation='relu')(merge)\n",
    "        self.altitude = keras.layers.BatchNormalization()(self.altitude)\n",
    "        self.altitude = keras.layers.Dense(1, activation='elu')(self.altitude)\n",
    "        self.altitude = keras.layers.BatchNormalization()(self.altitude)\n",
    "\n",
    "        # This placeholder will hold the root error edge values.\n",
    "        self.gradient_weights = tf.placeholder(tf.float32, shape=(1, None))\n",
    "\n",
    "        # Define optimizer\n",
    "        opt = tf.train.GradientDescentOptimizer(learning_rate=1e-7)\n",
    "\n",
    "        tvs = tf.trainable_variables()\n",
    "\n",
    "        loss = tf.matmul(self.gradient_weights, self.altitude)\n",
    "\n",
    "        # Accumulate gradients of predictions with respect to the parameters.\n",
    "        accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in tvs]\n",
    "        self.zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "        gvs = opt.compute_gradients(loss, tvs)\n",
    "        self.accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs)]\n",
    "\n",
    "        # Apply gradients\n",
    "        self.train_step = opt.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(gvs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_altitudes(chopin, static_images, dynamic_images):\n",
    "        \"\"\"\n",
    "        Predicts the altitude of one or more edges given the static image and the dynamic image.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            static_images: a numpy.ndarray of shape [None, receptive_field_shape[0],\n",
    "            receptive_field_shape[1], 2] images from the original image that are\n",
    "            augmented with boundary probabilities and are cropped to the same size\n",
    "            of the receptive field.\n",
    "\n",
    "            dynamic_images: a numpy.ndarray of rgb images of shape [None, receptive_field_shape[0],\n",
    "            receptive_field_shape[1], 3] that represent the relative assignments.\n",
    "\n",
    "        Returns:\n",
    "            The altitudes of the edges.\n",
    "        \"\"\"\n",
    "\n",
    "        with chopin.sess.as_default():\n",
    "            feed_dict = {chopin.static_input: static_images,\n",
    "                         chopin.dynamic_input: dynamic_images,\n",
    "                         keras.backend.learning_phase(): 0}\n",
    "\n",
    "            altitudes = chopin.sess.run(chopin.altitude, feed_dict)\n",
    "\n",
    "        return altitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimum_spanning_forest(self, I_a, graph, seeds):\n",
    "\n",
    "        num_nodes = graph.number_of_nodes()\n",
    "        visited = []\n",
    "        frontier = []\n",
    "\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "\n",
    "        relative_assignments = RelativeAssignments(seeds, (I_a.shape[0], I_a.shape[1]), self.receptive_field_shape)\n",
    "\n",
    "        print(\"Starting gradient segmentation...\")\n",
    "        start = time.time()\n",
    "\n",
    "        while len(visited) < num_nodes:\n",
    "\n",
    "            for u in seeds:\n",
    "\n",
    "                # Assign seed to self.\n",
    "                graph.node[u]['seed'] = u\n",
    "\n",
    "                relative_assignments.assign_node(u, seeds.index(u))\n",
    "\n",
    "                visited.append(u)\n",
    "\n",
    "                # Store path.\n",
    "                graph.node[u]['path'] = [u]\n",
    "\n",
    "                # Push all edges\n",
    "                for u, v in graph.edges(u):\n",
    "\n",
    "                    seed = graph.node[u]['seed']\n",
    "\n",
    "                    cropped_rgb = relative_assignments.get_node_image(v, seed)\n",
    "\n",
    "                    cropped_rgb = np.expand_dims(cropped_rgb, 0)\n",
    "\n",
    "                    cropped_image = utils.crop_2d(I_a, v, self.receptive_field_shape[0],\n",
    "                                                  self.receptive_field_shape[1])\n",
    "\n",
    "                    cropped_image = np.expand_dims(cropped_image, 0)\n",
    "\n",
    "                    altitude_value = self.predict_altitudes(cropped_image, cropped_rgb)\n",
    "\n",
    "                    graph.edge[u][v]['weight'] = altitude_value[0][0]\n",
    "                    try:\n",
    "                        graph.edge[u][v]['static_image'] = cropped_image\n",
    "                        graph.edge[u][v]['dynamic_image'] = cropped_rgb\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "                    del cropped_image, cropped_rgb\n",
    "\n",
    "                    push(frontier, (graph[u][v].get('weight', 1), u, v))\n",
    "\n",
    "            while frontier:\n",
    "                W, u, v = pop(frontier)\n",
    "\n",
    "                if v in visited:\n",
    "                    continue\n",
    "\n",
    "                # Assign the node\n",
    "                graph.node[v]['seed'] = graph.node[u]['seed']\n",
    "\n",
    "                relative_def minimum_spanning_forest(self, I_a, graph, seeds):\n",
    "\n",
    "        num_nodes = graph.number_of_nodes()\n",
    "        visited = []\n",
    "        frontier = []\n",
    "\n",
    "        push = heappush\n",
    "        pop = heappop\n",
    "\n",
    "        relative_assignments = RelativeAssignments(seeds, (I_a.shape[0], I_a.shape[1]), self.receptive_field_shape)\n",
    "\n",
    "        print(\"Starting gradient segmentation...\")\n",
    "        start = time.time()\n",
    "\n",
    "        while len(visited) < num_nodes:\n",
    "\n",
    "            for u in seeds:\n",
    "\n",
    "                # Assign seed to self.\n",
    "                graph.node[u]['seed'] = u\n",
    "\n",
    "                relative_assignments.assign_node(u, seeds.index(u))\n",
    "\n",
    "                visited.append(u)\n",
    "\n",
    "                # Store path.\n",
    "                graph.node[u]['path'] = [u]\n",
    "\n",
    "                # Push all edges\n",
    "                for u, v in graph.edges(u):\n",
    "\n",
    "                    seed = graph.node[u]['seed']\n",
    "\n",
    "                    cropped_rgb = relative_assignments.get_node_image(v, seed)\n",
    "\n",
    "                    cropped_rgb = np.expand_dims(cropped_rgb, 0)\n",
    "\n",
    "                    cropped_image = utils.crop_2d(I_a, v, self.receptive_field_shape[0],\n",
    "                                                  self.receptive_field_shape[1])\n",
    "\n",
    "                    cropped_image = np.expand_dims(cropped_image, 0)\n",
    "\n",
    "                    altitude_value = self.predict_altitudes(cropped_image, cropped_rgb)\n",
    "\n",
    "                    graph.edge[u][v]['weight'] = altitude_value[0][0]\n",
    "                    try:\n",
    "                        graph.edge[u][v]['static_image'] = cropped_image\n",
    "                        graph.edge[u][v]['dynamic_image'] = cropped_rgb\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "                    del cropped_image, cropped_rgb\n",
    "\n",
    "                    push(frontier, (graph[u][v].get('weight', 1), u, v))\n",
    "\n",
    "            while frontier:\n",
    "                W, u, v = pop(frontier)\n",
    "\n",
    "                if v in visited:\n",
    "                    continue\n",
    "\n",
    "                # Assign the node\n",
    "                graph.node[v]['seed'] = graph.node[u]['seed']\n",
    "\n",
    "                relative_assignments.assign_node(v, seeds.index(graph.node[u]['seed']))\n",
    "\n",
    "                # Store path.\n",
    "                graph.node[v]['path'] = graph.node[u]['path'] + [v]\n",
    "\n",
    "                visited.append(v)\n",
    "\n",
    "                for v, w in graph.edges(v):\n",
    "                    if not w in visited:\n",
    "\n",
    "                        seed = graph.node[v]['seed']\n",
    "\n",
    "                        cropped_rgb = relative_assignments.get_node_image(w, seed)\n",
    "\n",
    "                        cropped_rgb = np.expand_dims(cropped_rgb, 0)\n",
    "\n",
    "                        cropped_image = utils.crop_2d(I_a, w, self.receptive_field_shape[0],\n",
    "                                                      self.receptive_field_shape[1])\n",
    "\n",
    "                        cropped_image = np.expand_dims(cropped_image, 0)\n",
    "\n",
    "                        altitude_value = self.predict_altitudes(cropped_image, cropped_rgb)\n",
    "\n",
    "                        graph.edge[v][w]['weight'] = altitude_value[0][0]\n",
    "\n",
    "                        try:\n",
    "                            graph.edge[v][w]['static_image'] = cropped_image\n",
    "                            graph.edge[v][w]['dynamic_image'] = cropped_rgb\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "\n",
    "                        push(frontier, (graph[v][w].get('weight', 1), v, w))\n",
    "\n",
    "            end = time.time()\n",
    "            print(\"Segmentation done: %fs\" % (end - start))\n",
    "\n",
    "        del relative_assignments\n",
    "        del visited\n",
    "\n",
    "        return graphassignments.assign_node(v, seeds.index(graph.node[u]['seed']))\n",
    "\n",
    "                # Store path.\n",
    "                graph.node[v]['path'] = graph.node[u]['path'] + [v]\n",
    "\n",
    "                visited.append(v)\n",
    "\n",
    "                for v, w in graph.edges(v):\n",
    "                    if not w in visited:\n",
    "\n",
    "                        seed = graph.node[v]['seed']\n",
    "\n",
    "                        cropped_rgb = relative_assignments.get_node_image(w, seed)\n",
    "\n",
    "                        cropped_rgb = np.expand_dims(cropped_rgb, 0)\n",
    "\n",
    "                        cropped_image = utils.crop_2d(I_a, w, self.receptive_field_shape[0],\n",
    "                                                      self.receptive_field_shape[1])\n",
    "\n",
    "                        cropped_image = np.expand_dims(cropped_image, 0)\n",
    "\n",
    "                        altitude_value = self.predict_altitudes(cropped_image, cropped_rgb)\n",
    "\n",
    "                        graph.edge[v][w]['weight'] = altitude_value[0][0]\n",
    "\n",
    "                        try:\n",
    "                            graph.edge[v][w]['static_image'] = cropped_image\n",
    "                            graph.edge[v][w]['dynamic_image'] = cropped_rgb\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "\n",
    "                        push(frontier, (graph[v][w].get('weight', 1), v, w))\n",
    "\n",
    "            end = time.time()\n",
    "            print(\"Segmentation done: %fs\" % (end - start))\n",
    "\n",
    "        del relative_assignments\n",
    "        del visited\n",
    "\n",
    "        return graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
